:PROPERTIES:
:title: ğŸ”­ How to Reduce \#LLM Gen... (highlights)
:author: [[ShayneRedford on Twitter]]\
:full-title: "ğŸ”­ How to Reduce \#LLM Gen..."\
:category: #tweets\
:url: https://twitter.com/ShayneRedford/status/1628068629983150080\
:END:\

* Highlights first synced by [[Readwise]] [[2023-02-22]]
** ğŸ”­ How to reduce #llm generation toxicity/bias?

I'm surprised this finding hasn't received any attention:

Instruction Tuning (e.g. Flan, T0) reduces toxic generations A LOT âœ¨ w/o any Human Feedback âœ¨.

â¡ï¸ I.e. #ChatGPT-esque Human values alignment w/o human feedback.

1/ 

![](https://pbs.twimg.com/media/FpgPyQLaMAAu79D.jpg) 

![](https://pbs.twimg.com/media/FpgPyhWaEAEfsJe.jpg) ([View Tweet](https://twitter.com/ShayneRedford/status/1628068629983150080))
** Buried in the Scaling Flan Appendix C:

1âƒ£ Generating toxic responses to non-toxic prompts (ğŸ”» 44% â¡ï¸ 18%)
2âƒ£ Generating toxic responses to prompts on identity groups (ğŸ”»ğŸ”»)
3âƒ£ Ability to detect toxic content 0-shot (ğŸ”º14%+)

ğŸ“œ: https://t.co/lvYsx8kPfF

2/ ([View Tweet](https://twitter.com/ShayneRedford/status/1628068633904824320))
** ğŸŒŸ Finding 1âƒ£ ğŸŒŸ

RealToxicityPrompts measures how often toxic / non-toxic prompts trigger biased/toxic/profane responses (rated by Perspective API).

RTP ğŸ“œ: https://t.co/UcGsE9d8d0, @samgehman @ssgrn et al

Figures: Flan-PaLM's responses eval less toxic than PaLM's

3/ 

![](https://pbs.twimg.com/media/FpgPzE8agAAwcBV.png) 

![](https://pbs.twimg.com/media/FpgPzWVaMAAV0ag.jpg) ([View Tweet](https://twitter.com/ShayneRedford/status/1628068646508728320))
** ğŸŒŸ Finding 2âƒ£ ğŸŒŸ

Responses to prompts for identity groups are systematically less toxic for Flan-PaLM than PaLM.

Figures: Religion/Gender/Ethnicity toxicities lower (L), though tail distribution toxicities aren't solved (R).

4/ 

![](https://pbs.twimg.com/media/FpgPz5sagAIiu7Z.jpg) 

![](https://pbs.twimg.com/media/FpgP0QJaMAEQ8MP.jpg) ([View Tweet](https://twitter.com/ShayneRedford/status/1628068662275092482))
** ğŸŒŸ Finding 3âƒ£ ğŸŒŸ

LLMs' ability to identify whether text is toxic or not, using Civil Comments, is significantly improved (perhaps less surprising).

Civil Comments ğŸ“œ: https://t.co/IjLhkDqOWI

Table: Flan-PaLM > PaLM by ~13%+ for 0-shot, and ~5%+ for 10-shot.

5/ 

![](https://pbs.twimg.com/media/FpgP0x6aAAAhKyC.png) ([View Tweet](https://twitter.com/ShayneRedford/status/1628068670068133889))
** Why is this important?

New work shows larger models can harbor more bias (ğŸ“œ: https://t.co/TTKQC1MQot Ganguli, @AmandaAskell, @nschiefer et al.)

And larger models may hallucinate non-factual info more (https://t.co/cs8z1ka8Sz)

6/ 

![](https://pbs.twimg.com/media/FpgP1OwaYAAyb-E.jpg) 

![](https://pbs.twimg.com/media/FpgP1hNaAAYiH2b.jpg) ([View Tweet](https://twitter.com/ShayneRedford/status/1628068685456998400))
** ğŸŒŸ Take-aways ğŸŒŸ

Much of the discussion on "alignment to human values" has centered on collecting human feedback signals to model responses.

But the Flan Collection is simply NLP tasks framed as instructions...

7/ ([View Tweet](https://twitter.com/ShayneRedford/status/1628068689902972929))
** ğŸŒŸ Take-aways ğŸŒŸ

This isn't to say human feedback doesn't provide stronger benefits, but significant toxicity reduction (or better #AISafety) may be achievable with the tools we already have (simple instruction tuning), even without new large-scale collection efforts.

8/ ([View Tweet](https://twitter.com/ShayneRedford/status/1628068692562186242))
** ğŸŒŸ Take-aways ğŸŒŸ

TLDR: Care about bias/toxicity? Use your favorite instruction-tuned model.

(Like Flan-T5: https://t.co/p7gVis9lHM!)

9/ ([View Tweet](https://twitter.com/ShayneRedford/status/1628068695154229249))
** ğŸŒŸ Limitations ğŸŒŸ

â¡ï¸ Toxicity evals are imperfect and not comprehensive!
â¡ï¸ These evals are only English and western-centric
â¡ï¸ Review the paper for important details

10/ ([View Tweet](https://twitter.com/ShayneRedford/status/1628068697763115009))
** Extra credit goes to Kevin Robinson, @Hou_Le, @m_pellat, Dasha Valter, @acastroros who ran these evals.

11/11 ([View Tweet](https://twitter.com/ShayneRedford/status/1628068700443246597))
** And thank you to @_jasonwei and @YiTayML for feedback on this thread! ([View Tweet](https://twitter.com/ShayneRedford/status/1628068917708050433))