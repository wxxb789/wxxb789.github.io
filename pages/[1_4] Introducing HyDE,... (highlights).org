:PROPERTIES:
:title: [1_4] Introducing HyDE,... (highlights)
:author: [[@luyu_gao on Twitter]]
:full-title: "[1/4] Introducing HyDE,..."
:category: #tweets
:url: https://twitter.com/luyu_gao/status/1605232516817752065
:END:

* Highlights first synced by [[Readwise]] [[2022-12-21]]
** [1/4] Introducing HyDE, a method to unsupervisedly build dense retrievers. HyDE zero-shot instructs GPT to generate a fictional document and re-encodes it with Contriever to search in its embedding space. Put it simply, casting retrieval-like behavior in GPT into real retrieval. 

![](https://pbs.twimg.com/media/FkbuYrEXgAAHl5r.jpg) ([View Tweet](https://twitter.com/luyu_gao/status/1605232516817752065))
** [2/4] With zero training/fine-tuning, HyDE significantly outperforms its backbone Contriever across tasks and languages. On several query sets, it even shows better performance than strong fine-tuned models. 

![](https://pbs.twimg.com/media/FkbujhZWAAEQJid.png) 

![](https://pbs.twimg.com/media/FkbujhiWAAAfqen.png) 

![](https://pbs.twimg.com/media/FkbujhzWYAAGQWV.png) ([View Tweet](https://twitter.com/luyu_gao/status/1605232631502831618))
** [3/4] One of the most interesting problems we encountered while working on this was: if strong generative models can largely improve sole retrieverâ€™s performance, should we shift the responsibility of high precision away from the retriever. ([View Tweet](https://twitter.com/luyu_gao/status/1605232723525787648))
** [4/4] Work led by @xueguang_ma and me, with @lintool @JamieCallan

PDF: https://t.co/MMjTBxVDav
Code: https://t.co/mzdzU659dB (notebook now, more to come)
- No model is trained/fine-tuned; find here the inference code. ([View Tweet](https://twitter.com/luyu_gao/status/1605232857999241216))