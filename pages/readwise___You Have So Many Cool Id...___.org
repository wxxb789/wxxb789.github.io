:PROPERTIES:
:title: readwise/You Have So Many Cool Id...
:END:


* metadata
:PROPERTIES:
:author: [[CohereAI on Twitter]]
:full-title: "You Have So Many Cool Id..."
:category: [[tweets]]
:url: https://twitter.com/CohereAI/status/1639266541505052676
:image-url: https://pbs.twimg.com/profile_images/1650250832909152260/760DZ0cv.png
:END:

* Highlights first synced by [[Readwise]] [[2023-12-22]]
** ğŸ“Œ [[2023-04-13]]
#+BEGIN_QUOTE
You have so many cool ideas for building LLM-powered applications. If only there were a faster way to build and test them out. âš¡

Good news â€” you can do that with Cohere and @LangChainAI. Letâ€™s see how. (Thread) 

![](https://pbs.twimg.com/media/Fr_YO39XwAAL_Wo.png) 
#+END_QUOTE\
** ğŸ“Œ [[2023-04-13]]
#+BEGIN_QUOTE
@LangChainAI With Cohere, you get access to large language models (LLMs) via a simple API without needing the machine learning know-how.

You get two key types of language processing capabilities â€” text generation and text embedding â€” each served by a different family of models. 

![](https://pbs.twimg.com/media/Fr_YPPoWIAMkTTp.png) 
#+END_QUOTE\
** ğŸ“Œ [[2023-04-13]]
#+BEGIN_QUOTE
@LangChainAI With Langchain, itâ€™s fast and easy to combine LLMs with other sources of computation or knowledge.

You can quickly put together an end-to-end application via its wide range of modules. 

![](https://pbs.twimg.com/media/Fr_YPiTWcAEDnDS.png) 
#+END_QUOTE\
** ğŸ“Œ [[2023-04-13]]
#+BEGIN_QUOTE
@LangChainAI Letâ€™s use a simple example involving multilingual semantic search.

First, what is semantic search?

It gives you search capabilities based on contextual meaning and solves the limitations of the alternative method, which is keyword search. 
#+END_QUOTE\
** ğŸ“Œ [[2023-04-13]]
#+BEGIN_QUOTE
@LangChainAI Meanwhile, with multilingual search, you can search across multiple languages.

But this typically involves creating individual pipelines for each language, making it costly to build.

With Cohereâ€™s multilingual embedding model, you need just one model to handle 100+ languages. 
#+END_QUOTE\
** ğŸ“Œ [[2023-04-13]]
#+BEGIN_QUOTE
@LangChainAI When talking about multilingual search, more precisely there are two types: multilingual and cross-lingual.

With Cohereâ€™s multilingual embedding model, you can do both. 

![](https://pbs.twimg.com/media/Fr_YQErWwAoW6OS.png) 
#+END_QUOTE\
** ğŸ“Œ [[2023-04-13]]
#+BEGIN_QUOTE
@LangChainAI Now letâ€™s get to our example.Â 

Weâ€™ll create a semantic search pipeline for searching the most relevant documents from a list of documents.

Weâ€™ll see how the model does at cross-lingual search. 

![](https://pbs.twimg.com/media/Fr_YQYPWYAYhmHY.png) 
#+END_QUOTE\
** ğŸ“Œ [[2023-04-13]]
#+BEGIN_QUOTE
@LangChainAI Step 1: Import a List of Documents

First we import a dataset containing a list of questions from the Text REtrieval Conference (TREC) Question Classification dataset.

It contains 5,452 documents. Here are a few examples: 

![](https://pbs.twimg.com/media/Fr_YQu7WAAI6H6D.jpg) 
#+END_QUOTE\
** ğŸ“Œ [[2023-04-13]]
#+BEGIN_QUOTE
@LangChainAI We can get the dataset from the publicly available Tensorflow Datasets library. 

![](https://pbs.twimg.com/media/Fr_YRABWIAg5exo.jpg) 
#+END_QUOTE\
** ğŸ“Œ [[2023-04-13]]
#+BEGIN_QUOTE
@LangChainAI Step 2: Embed the Documents and Store Them in an Index

Next is where the magic happens. Using the multilingual-22-12 model, we turn the documents into text embeddings and store them in a database. Here, we use Chroma.

With Langchain, we can do that in just two lines of code. 

![](https://pbs.twimg.com/media/Fr_YRYIXoAk8LNm.jpg) 
#+END_QUOTE\
** ğŸ“Œ [[2023-04-13]]
#+BEGIN_QUOTE
@LangChainAI Step 3: Enter a Query

We enter a new search query: â€œHow to get in touch with Bill Gates.â€

Now, in the dataset, there are three items that contain â€œBill Gatesâ€, but none contains â€œget in touch.â€ A traditional keyword search canâ€™t easily distinguish the most relevant one. 

![](https://pbs.twimg.com/media/Fr_YRw7WAAIrWbH.jpg) 
#+END_QUOTE\
** ğŸ“Œ [[2023-04-13]]
#+BEGIN_QUOTE
@LangChainAI However, with semantic search, we should expect to get  â€œWhat is Bill Gates of Microsoft email address?â€ as the most similar one because â€œget in touchâ€ and â€œemail addressâ€ imply a similar intent. 
#+END_QUOTE\
** ğŸ“Œ [[2023-04-13]]
#+BEGIN_QUOTE
@LangChainAI But letâ€™s not stop there. The multilingual model can also perform well at cross-lingual tasks. So, weâ€™ll enter the same query in three other languages: French, Hindi, and Indonesian. 

![](https://pbs.twimg.com/media/Fr_YSHpXgAY_Sx8.jpg) 
#+END_QUOTE\
** ğŸ“Œ [[2023-04-13]]
#+BEGIN_QUOTE
@LangChainAI Step 4: Return the Document Most Similar to the Query

Now, we take the query and pass through Langchainâ€™s similarity_search method to get the document most similar to the query. 

![](https://pbs.twimg.com/media/Fr_YSabXwAA5-Xs.jpg) 
#+END_QUOTE\
** ğŸ“Œ [[2023-04-13]]
#+BEGIN_QUOTE
@LangChainAI And below are the results for the query in the four languages. It successfully finds the most semantically similar document to the query. 

![](https://pbs.twimg.com/media/Fr_YSukWIAUKe4D.jpg) 
#+END_QUOTE\
** ğŸ“Œ [[2023-04-13]]
#+BEGIN_QUOTE
@LangChainAI In that example, we saw an example of building:
1 - A cross-lingual semantic search engine using just one embedding model (Cohere)
2 - A complete pipeline in just a few lines of code (Langchain) 
#+END_QUOTE\
** ğŸ“Œ [[2023-04-13]]
#+BEGIN_QUOTE
@LangChainAI Now, what if we wanted to use semantic search to answer questions about a document?Â 

It could be a long-form document, such as an article, or even multi-page documents, such as a docs website. 
#+END_QUOTE\
** ğŸ“Œ [[2023-04-13]]
#+BEGIN_QUOTE
@LangChainAI Thatâ€™s an example of search-based question answering, combining text embedding and text generation.

We show an example of that in our blog post: https://t.co/L2C8pAnd2y 
#+END_QUOTE\