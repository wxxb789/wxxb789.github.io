:PROPERTIES:
:title: readwise/Over the Past Weeks The...
:END:


* metadata
:PROPERTIES:
:author: [[Thom_Wolf on Twitter]]
:full-title: "Over the Past Weeks The..."
:category: [[tweets]]
:url: https://twitter.com/Thom_Wolf/status/1717821614467739796
:image-url: https://pbs.twimg.com/profile_images/1629469939860946946/WUyBolSu.jpg
:END:

* Highlights first synced by [[Readwise]] [[2023-12-22]]
** ğŸ“Œ [[2023-10-27]]
#+BEGIN_QUOTE
Over the past weeks the H4 team has been busy pushing the Zephyr 7B model to new heights ğŸ—»

The new version is now topping all 7b models on chat evals and even 10x larger models ğŸ¤¯ğŸ”¥

Here are the intuitions on it

1/ Start with the strongest pretrained model you can find: Mistral 7B is amazing, by far the strongest 7B pretrained model. Props to the Mistral AI team ğŸ˜

2/ Scale human-preference annotations: several studies have show how for many tasks GPT4 is on-par with the average human annotators while making scalable annotations as easy as an API call: the H4 team started from the largest and most diverse public GPT4 preference annotation dataset: UltraFeedback ğŸ¤–ğŸ¦¾

3/ Drop Reinforcement Learning in favor of DPO (Direct Preference Optimization): while using LLM in RL is definitely much easier compared to the struggles of getting deep-RL to work from scratch, DPO totally remove RL from the preference annotation training and directly optimize the preference model in a much more stable training procedure in the H4 team's experiments

4/ Don't be scared of overfitting on preference dataset: This is maybe the most counterintuitive results of the work. While the train/test loss of DPO training shows signs of overfitting on the feedback dataset after just one epoch, training further still show significant improvements on downstream tasks even up to 3 epochs without signs of performances regression. Would be interesting to dive even further in this surprising behavior

5/ Share everything openly ğŸ˜ the recipes, code, model and dataset will be available at https://t.co/qkKhS8eqvt 
In the meantime the paper is a great starting point: https://t.co/qzZ0tb8Aq1<img src='https://pbs.twimg.com/media/F9brn0CXkAMj6pd.jpg'/> 
#+END_QUOTE\