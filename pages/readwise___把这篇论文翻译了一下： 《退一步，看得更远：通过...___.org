:PROPERTIES:
:title: readwise/把这篇论文翻译了一下： 《退一步，看得更远：通过...
:END:

:PROPERTIES:
:author: [[dotey on Twitter]]
:full-title: "把这篇论文翻译了一下： 《退一步，看得更远：通过..."
:category: [[tweets]]
:url: https://twitter.com/dotey/status/1717753585771950250
:image-url: https://pbs.twimg.com/profile_images/561086911561736192/6_g58vEs.jpeg
:END:

* Highlights first synced by [[Readwise]] [[2023-12-18]]
** 📌
#+BEGIN_QUOTE
把这篇论文翻译了一下：
《退一步，看得更远：通过抽象引发大型语言模型中的推理》Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models
https://t.co/deedtBho8r

什么是退一步提示法？

退一步提示这个方法的灵感来自于一个观察：很多任务都很复杂，充满了细节，让大语言模型（LLMs）很难找到解决问题所需的相关信息。比如在图 2 的第一个例子中，一个关于物理的问题：“如果一个理想气体的温度翻了一番，体积增加了八倍，那么它的压强 P 会发生什么变化？”LLM 在直接解答这个问题时可能会忽略理想气体定律的基本原则。类似地，一个询问“Estella Leopold 在 1954 年 8 月到 11 月期间就读于哪所学校？”的问题，由于时间范围非常具体，直接回答也是非常困难的。在这两种情况下，通过退一步提问，我们能够帮助模型更有效地解决问题。

我们定义退一步问题为从原始问题中派生出来的、层级更高的抽象问题。比如，不直接问“Estella Leopold 在特定时间段内的学校是哪所”，我们可以问一个更高层次的问题：“Estella Leopold 的教育历史是怎样的？”（如图 2 下方所示）。通过回答这个更抽象的问题，我们能获得解答原始问题所需的所有信息。通常来说，退一步问题比原始问题更容易回答。基于这种抽象层次的推理有助于避免中间步骤的错误，就像图 2 中左侧的链式思维提示的例子一样。总的来说，退一步提示包含两个简单的步骤：

1. 抽象：我们首先提示 LLM 提出一个关于更高层次概念或原则的通用问题，并检索与之相关的信息，而不是直接回答原始问题。
2. 推理：在获取了关于高层次概念或原则的信息后，LLM 可以基于这些信息对原始问题进行推理。我们将这种方法称为基于抽象的推理。
在接下来的部分，我们将展示在一系列复杂的 STEM、知识问答和多步推理任务上对退一步提示方法的实证研究。<img src='https://pbs.twimg.com/media/F9au9YSWcAAM8jT.jpg'/><img src='https://pbs.twimg.com/media/F9avOESXgAEQ6xs.jpg'/><img src='https://pbs.twimg.com/media/F9avRVQWoAA2MMP.png'/> 
#+END_QUOTE
    date:: [[2023-10-27]]
*** from _把这篇论文翻译了一下： 《退一步，看得更远：通过..._ by @dotey on Twitter
*** [View Tweet](https://twitter.com/dotey/status/1717753585771950250)