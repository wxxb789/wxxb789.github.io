:PROPERTIES:
:title: (readwise)ğŸ¤–ï¸LLM Can Self-Improve ğŸ§ ...
:END:

:PROPERTIES:
:author: [[jkronand on Twitter]]
:full-title: "ğŸ¤–ï¸LLM Can Self-Improve ğŸ§ ..."
:category: [[tweets]]
:url: https://twitter.com/jkronand/status/1621744876298833920
:image-url: https://pbs.twimg.com/profile_images/1635756469986689024/lPOWrGg5.jpg
:END:

* Highlights first synced by [[Readwise]] [[2023-12-05]]
** ğŸ“Œ
#+BEGIN_QUOTE
ğŸ¤–ï¸LLM can self-improve ğŸ§ 

1) Self-consistency boosts reasoning skills by sampling multiple paths & finding the most consistent answer

But more samples = more comp. requirements. ğŸ’»

2)  but we can train better LLM with self-generated solutions from 1)

https://t.co/kLfyCuc0uL 
#+END_QUOTE
    date:: [[2023-02-05]]
*** from _ğŸ¤–ï¸LLM Can Self-Improve ğŸ§ ..._ by @jkronand on Twitter
*** [View Tweet](https://twitter.com/jkronand/status/1621744876298833920)
** ğŸ“Œ
#+BEGIN_QUOTE
The naive approach requires:

\- dataset of unlabeled questions
- few-shot chain of thought prompts to generate the "pseudo" labels for the self-train pass

Authors show one can also extend a dataset with synthetic questions, to get more pseudo labels, and improve results further 
#+END_QUOTE
    date:: [[2023-02-05]]
*** from _ğŸ¤–ï¸LLM Can Self-Improve ğŸ§ ..._ by @jkronand on Twitter
*** [View Tweet](https://twitter.com/jkronand/status/1621745961444986880)