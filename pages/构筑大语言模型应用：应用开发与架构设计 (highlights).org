:PROPERTIES:
:title: 构筑大语言模型应用：应用开发与架构设计 (highlights)
:END:

:PROPERTIES:
:author: [[phodal.com]]
:full-title: "构筑大语言模型应用：应用开发与架构设计"
:category: [[articles]]
:url: https://aigc.phodal.com/misc/faq.html
:END:

* Highlights first synced by [[Readwise]] [[2023-07-12]]
** 📌
** #+BEGIN_QUOTE
** **狭义的 Prompt 工程**专注于 AI 领域的 Prompt 优化，即通过优化任务描述来提高自然语言处理模型的性能。典型的做法是将一个或多个任务转换为基于提示的数据集，并通过所谓的“基于提示的学习”来训练语言模型。这有助于训练大型语言模型 ( LLM)，使 AI 能更好地理解需求并完成专业任务。

**广义的 Prompt 工程师**则是指针对 AI 模型编写 Prompt 的人，以获得更好的结果。他们需要找到合适的提示词，让 AI 发挥出最大潜力。这个角色可以分为两部分：面向大语言模型的工程师和面向落地应用的工程师。

**从使用 AI 模型的角度看**。随着 AI 技术的发展和普及，对 AI 模型的需求可能会逐渐减弱。这是因为随着模型的不断优化，它们的理解能力和性能将不断提高，使得在许多情况下无需额外的 Prompt 工程即可满足需求。然而，这并不意味着 Prompt 工程没有未来。相反，随着 AI 在越来越多的领域得到应用，Prompt 工程仍然可以为特定任务和领域提供有针对性的优化。

**从工程侧的角度看**。大型公司可能需要一两位专家来指导开发人员进行 Prompt 工程。通过组织活动（如 hackathon），公司可以提高开发人员对 Prompt 工程的意识，帮助他们结合 Prompt 开发应用，以实现工程化落地。尽管大部分开发人员可能还没有充分认识到 Prompt 工程的重要性，但随着时间的推移，这一情况有望得到改善。 ([View Highlight](https://read.readwise.io/read/01h54kxntmpfc990f1aqb3bg8p))
** #+END_QUOTE
** 📌
** #+BEGIN_QUOTE
** **结论**

综上所述，工程在狭义和广义上都有一定的未来。尽管随着 AI 技术的进步，使用 AI 模型的需求可能会逐渐减弱，但 Prompt 工程仍然可以为特定任务和领域提供有针对性的优化。此外，大型公司需要专家指导开发人员进行 Prompt 工程，提高他们的意识并实现工程化落地。因此，Prompt 工程在未来仍然具有一定的发展空间和潜力。

同时我们看到，很多企业的AI2.0起步都将从Prompt工程开始，不同行业不同的融入节奏下，会使得Prompt工程在未来很长一段时间内都很重要。 ([View Highlight](https://read.readwise.io/read/01h54kxsb19xv4ph8q5cwga68j))
** #+END_QUOTE
** 📌
** #+BEGIN_QUOTE
** [什么时候考虑微调？](https://aigc.phodal.com/misc/faq.html#什么时候考虑微调)

微调（fine-tuning）通常是在已经预训练好的模型的基础上，使用特定的数据集进行进一步训练，以适应特定的任务或应用场景。通常情况下，微调会在以下情况下进行考虑：

1.  适应特定的任务或领域：预训练的模型通常是在大规模通用语料库上进行训练的，而在特定的任务或领域中，可能需要使用更具体的语言模式和领域知识。这时候，就需要使用微调的方式对模型进行进一步训练，以适应特定的任务或领域。
2.  数据集与预训练数据的差异较大：如果预训练的模型的训练数据与实际应用场景的数据差异较大，那么使用微调的方式可以更好地适应实际场景的数据分布，提高模型的性能。
3.  进一步提高模型的性能：在一些对模型性能要求较高的任务中，使用微调的方式可以进一步提高模型的性能，从而更好地满足实际应用需求。

然而，ChatGPT 总结的并不好，当你要考虑微调的时候，你应该考虑的是：

1.  ROI。微调的成本是很高的 —— 准备数据、训练模型、调参、部署，并进行持续的模型优化。
2.  好的基础模型。如果你的基础模型不够好，微调也不会有很好的效果。诸如于 LLaMA 7B 的中文效果不好。
3.  工程能力。微调的过程中，你需要有很好的工程能力，包括数据处理、模型训练、模型部署等等。

除此，在你没有思考清楚上述三点的时候，你不应该考虑微调。 ([View Highlight](https://read.readwise.io/read/01h54ky2vxc5jswjz9rqvadnfw))
** #+END_QUOTE
** 📌
** #+BEGIN_QUOTE
** [个人的策略？](https://aigc.phodal.com/misc/faq.html#个人的策略)

对于我来说，我的 AI 策略大致是：

1.  拥抱变化，尽管人工智能并不能完全代替人类，但它已经能够大大提高效率。
2.  强化构架能力，因为人工智能工具无法代替个人的感性思考和直觉。
3.  构建领域小模型，可以快速训练出一个专门用于解决自己问题的小型模型。
4.  探索与磨炼技巧，探索 AI 能力并持续构建小工具，来修复和完善自己的 AI 增强系统。

对于修复与完善来说，由于 AI 本身是无法达到这么精细的，所以我的想法是**持续构建小工具**。 ([View Highlight](https://read.readwise.io/read/01h54kykymd5xa3pg9barxax8v))
** #+END_QUOTE
* New highlights added [[2023-07-12]] at 5:48 PM
** 📌
** #+BEGIN_QUOTE
** AI 生成图片：

•   Stable Diffusion Webui GitHub： https://github.com/AUTOMATIC1111/stable-diffusion-webui
•   通用的 AI 模型社区：https://huggingface.co/
•   Stable Diffusion AI 艺术模型社区：https://civitai.com/ （18 禁）

代码模型相关：

•   Salesforce 模型：https://huggingface.co/Salesforce/codegen-6B-mono
•   CarpserAI： https://huggingface.co/CarperAI/diff-codegen-6b-v2

ControlNet 加强：

•   模型：https://huggingface.co/lllyasviel/ControlNet
•   预编译：https://huggingface.co/kohya-ss/ControlNet-diff-modules ([View Highlight](https://read.readwise.io/read/01h54q5hfe6r1r4w0wa42ehdz2))
** #+END_QUOTE
* New highlights added [[2023-07-12]] at 6:35 PM
** 📌
** #+BEGIN_QUOTE
** 尽管现有的 AI 工具都是多模态的，然而自然语言是作为中间语言存在的。所以，我想将文本形式的 prompt 称为**标准的 Prompt 即代码**，它可以方便地融入现有的编程体系。

•   Prompt 即注释。Prompt 作为注释与代码并存，在这种情况下，Prompt 与代码共存于同一个文件中。通常，Prompt 以注释的形式出现在代码中，以提供必要的上下文信息和生成代码的指令。这种方式适合于需要经常手动修改生成的代码的场景。
•   Prompt 即接口。在这种情况下，Prompt 作为一个标准的接口，代码则是实现这个接口的生成代码。这种方式适用于对生成的代码进行自动化测试和部署的场景，因为接口定义的一致性可以更好地保证代码的正确性。
•   Prompt 即代码。在这种情况下，版本管理工具中不再存储代码，而是存储 Prompt。生成的代码则可以根据 Prompt 来生成，Prompt 作为代码的一部分。这种方式适合于需要频繁更新代码和对代码进行版本控制的场景。

而，事实上，在我第一次将注释加入到 ClickPrompt 中的时候，我犹豫了很久。我们的过去的编程习惯，并不允许将思考过程作为注释到其中。

既然，它已经作为代码的一部分加入进来 ，我们还需要进一步考虑的点是：**尽可能地去修改 prompt 重新生成代码，减少直接修改 prompt**。 ([View Highlight](https://read.readwise.io/read/01h54s98dj3rx0qvrdvnqr7gnb))
** #+END_QUOTE