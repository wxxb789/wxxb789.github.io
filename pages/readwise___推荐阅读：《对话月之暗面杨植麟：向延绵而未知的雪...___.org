:PROPERTIES:
:title: readwise/推荐阅读：《对话月之暗面杨植麟：向延绵而未知的雪...
:END:


* metadata
:PROPERTIES:
:author: [[dotey on Twitter]]
:full-title: "推荐阅读：《对话月之暗面杨植麟：向延绵而未知的雪..."
:category: [[tweets]]
:url: https://twitter.com/dotey/status/1763427684485333449
:image-url: https://pbs.twimg.com/profile_images/561086911561736192/6_g58vEs.jpeg
:END:

* Highlights first synced by [[Readwise]] [[2024-03-08]]
** 📌 [[2024-03-06]]
#+BEGIN_QUOTE
推荐阅读：《对话月之暗面杨植麟：向延绵而未知的雪山前进》

就在一年以前，AI科学家杨植麟在硅谷做了一笔精确的计算。他意识到，如果决定启动一场以AGI为目标的大模型创业，要在未来几个月立马筹措超1亿美金资本。

然而，这仅仅只是一张入场券。一年后，这个数字翻了13倍。

大模型公司的竞争，与其说是一场科学竞争，不如说首先是一场残酷的金钱角力。在资本方捂紧口袋的情况下，你要领先对手找到更多的钱，购买更多的卡，抢夺更多的人才。

“它需要人才聚集、资本聚集。”成立于2023年3月1日的大模型公司月之暗面（Moonshot AI）创始人兼CEO杨植麟说。

过去一年，国产大模型公司似乎处在一种紧迫而逼仄的生存边缘。看上去，他们每个都手握重金。但一方面，他们要把刚融的钱，立马投入极高昂的科研中追赶OpenAI——先是追齐GPT-3.5，没等追上GPT-4，Sora又来了；另一方面，他们要马不停蹄在落地场景上找可能，自我验证你是一家公司、而不是只会吞噬资本金的研究所；这还不够，每个项目不管是上市还是并购，出路更是毫不明朗。

在中国大模型创始人中，杨植麟年纪最轻，于1992年出生。业界评价他是坚定的AGI信徒和有技术号召力的创始人。他的学习与工作履历很多与通用AI相关，论文引用超22000次。

对于大模型，中国科技界于2023年中从狂热骤然转冷，进入加速落地的实用主义主旋律。这不免让大模型CEO们处于理想与现实的剧烈拉扯之间。在人人喊PMF（Product/Market Fit，产品/市场契合）、人人喊商业化的中国AI生态里，这位AI研究员出身的创始人倒不那么着急。

月之暗面是头部国产大模型公司中，人数最少的一家，为80人。他没有像他的对手那样，做更稳妥的to B生意，或是在医疗、游戏等细分场景中找落地，而是做且只做了一款to C产品——智能助手Kimi，支持20万汉字输入。Kimi也是杨植麟的英文名。

杨植麟倾向于将他的公司看作是，构建一个结合科学、工程和商业的系统。你可以想象成，他要在人类世界上空，架起一张AI实验台，一手做实验，一手将尖端技术落进真实世界，通过与人类互动找到应用机会，再将应用送入消费者手中。理想状况是，前者烧掉数以十亿、百亿计资本；后者再把这些钱数成百上千倍地挣回来——怎么听，都像“走钢丝”一样惊险。

“AI不是我在接下来一两年找到什么PMF，而是接下来十到二十年如何改变世界。”他说。

这种抽象和理想主义的思考，令人不免替他捏一把冷汗：一位年轻的AI科学家，在现实主义的中国能否找到生存空间？

2024年2月，月之暗面逆势完成一笔大额融资。据了解，它以15亿美金投前估值完成超10亿美元B轮，阿里领投，砺思资本、小红书等跟投，该笔交易完成后，月之暗面投后估值约25亿美元——由此，它成为中国大模型赛场上现阶段估值最高的一家独角兽。（他们拒绝回应和评论此事。）

就在第三笔融资的过程中，我们和杨植麟聊了聊他过去一年创业故事，这也是国产大模型抢跑一年的截面缩影。

他的公司没有选址在大模型企业聚集地，北京搜狐网络大厦。对于一家融资总额约90亿元人民币的公司，这间位于量子芯座的办公室，显得简陋又破旧。门口连公司logo都没有，只有一架白色钢琴守在门口。

会议室在一个角落，由于窗户小黑漆漆的，冬天送来暖风的空调机器嗡嗡作响。暗沉的光亮中，杨植麟形容自己过去一年的感知：“有点像开车在路上，前面有延绵的雪山，但你不知道里面是什么，你在一步一步往前走。”

以下是对杨植麟的访谈全文。

https://t.co/zMbYR9GiKt 
#+END_QUOTE\
** 📌 [[2024-03-06]]
#+BEGIN_QUOTE
01 站在开端，要 ride the wave

腾讯新闻：最近你的状态怎么样？

杨植麟：忙啊，事情很多。但还是很兴奋。站在产业开端，有巨大想象空间。

腾讯新闻：我刚进来看到你们公司门口放了一架纯白色钢琴。

杨植麟：上面还有一张Pink Floyd专辑。我都不知道谁放的，前两天突然看到，没来得及问。（Pink Floyd是发布专辑《月之暗面》的英国摇滚乐队）

腾讯新闻：2022年11月，ChatGPT发布那天，你在做什么？

杨植麟：我正在筹备这个事，找人组团队，碰撞一些新认知。看到ChatGPT很激动。放到三五年前，甚至2021年，都是不可思议的。这种高阶推理能力过去很难做到。

我预感市场会发生很多变量：一方面是资本，一方面是人才，这是做AI的核心生产要素。如果变量成立，我们就有可能正儿八经搞一家公司做这件事——一个为AGI搭建的组织从0到1存在可能性，这是很大的顿悟。独立公司更make sense，但不是你想做马上就能做，ChatGPT刺激了变量，使生产要素齐全。还是要ride the wave。

腾讯新闻：你在决定创立一家AGI公司后，做了哪些准备？怎么凑齐资本和人才这两个生产要素？

杨植麟：是曲折的过程。ChatGPT扩散需要时间。有的人知道得早，有的人知道得晚，有的人一开始怀疑、后面变成震惊、再变成相信。找人找钱，跟timing结合得很紧。

我们2023年2月开始集中做第一轮融资。如果delay（延迟）到4月，基本没机会了。但如果2022年12月或2023年1月做也没机会，当时有疫情，大家没反应过来——所以，真正窗口就是一个月。

当时，在美国有一个晚上，我做了精确的计算。算完觉得至少要在几个月内拿到1亿美元。市场上很多人没开始融资，很多人觉得你这个不一定能融这么多钱。但后来证明是可以的，甚至比这个更多。

人才市场开始流动。受ChatGPT启发，很多人在2023年3月或4月有这样的realization（意识）：这是接下来十年唯一值得做的。要在正确时间积极触达对的人。如果是前两年，人才聚集度不会这么高。那时更多人做传统AI，或者跟AI相关的业务，都不是通用AI。

腾讯新闻：总结一下，2月是融资的窗口期，3月、4月是招人的窗口期？

杨植麟：差不多。

腾讯新闻：你在美国那一晚是在哪算了这笔账？具体怎么算的？

杨植麟：22年底到23年初，我在美国待了一两个月，找人聊。

在我住的地方。算一下你对应多少FLOPs（Floating Point Operations，每秒浮点运算次数）、Training Cost（训练成本）、Inference（推理）、用户量。

腾讯新闻：彼时彼刻，硅谷沉浸在什么样的情绪中？

杨植麟：这个产品开始有很多early adopters（早期用户），集中在技术圈，我们本身在这个圈子，感受更深刻。硅谷大厂每半年要写performance review（绩效评估），开始很多人用ChatGPT写。有的人平时写的语言不大professional（专业），用ChatGPT写，大家都一本正经的样子。

暗流涌动。很多人考虑下一份工作去哪或者创业。很多和我们聊的朋友后来纷纷创业。而且，有很强FOMO情绪（Fear of Missing Out，害怕错过）。所有人每天睡不着觉。不管晚上12点、1点、2点，你去找，always大家都在。有点焦虑，有点FOMO，又很兴奋。

腾讯新闻：算出要融1亿美金那晚，你算到了几点？

杨植麟：还好吧，计算过程倒不用很久。

但算完我也不能跟太多人说。说了也没有人觉得这事可以做。 
#+END_QUOTE\
** 📌 [[2024-03-06]]
#+BEGIN_QUOTE
02 技术师承 —— “把自己以无限雕花中释放出来”

腾讯新闻：创投行业提到你会说，“创始人很聪明，有技术号召力，团队里也有很多技术明星”。所以，聊大模型创业之前，想先聊聊你的学术背景。

你本科是清华计算机系，博士是卡耐基梅隆计算机学院，方向一直是AI吗？

杨植麟：我是92年出生，11级本科，大二到现在十多年一直在这个方向。一开始偏发散的探索，到处看看，跟图或多模态都做过一些，2017年收敛到语言模型——当时觉得语言模型是比较重要的问题，后来觉得它是唯一重要的问题。

腾讯新闻：2017年AI业界对语言模型普遍是怎样的认知，后来如何演进？

杨植麟：它（当时）是用来给语音识别做排序的模型。（笑）当你识别完一段语音，有很多结果，拿语言模型看到底哪个概率更大，输出最有可能的结果，应用非常有限。

但你发现它是根本问题，因为你在对这个世界概率建模。虽然语言局限，它是世界的投映；但理论上你把token space（所有可能的标记组成的空间）做得更大，就可以构建一个通用世界模型。世界上每样东西怎么产生、发展，都能给它分配一个概率。所有问题都可以被归结成怎么对概率估计。

腾讯新闻：你学术生涯的导师很有名，博士导师是苹果公司AI负责人Ruslan Salakhutdinov和Google AI智能首席科学家William W. Cohen。他们都既在产业界，又在学界。

杨植麟：产业界和学术界从前几年有更多结合，现在趋势在变化：更多有价值的突破会产生在工业界，这是发展的必然规律。先从探索性研究开始，逐渐转移到更成熟的工业化过程，但不意味着工业化过程中不需要研究，只是纯研究会很难做出有价值的突破。

腾讯新闻：从这几位颇有名望的导师身上学到了什么？

杨植麟：我学习到最多是在Google，实习了很长时间。2018年底开始做基于Transformer的语言模型，最大learning是从无限雕花中把自己释放出来，这很关键。

应该看什么是大方向、大梯度。当你眼前有十条路，一般人考虑我走这条路前面有一个行人怎么刹车，是短期细节，但这十条路到底选哪一条最重要。

这个领域在之前有这样的问题。比如，在只有一两百万token（标记）的数据集上，看perplexity（困惑度，衡量模型在预测序列时的不确定性或混乱度）怎么降得更低，loss（损失，模型在训练过程中的误差或损失函数的值）怎么降得更低，怎么提升准确率，你会陷入无限雕花。有人发明很多诡异的architecture（架构），这些是雕花技巧。雕花之后可能在这种数据集上变好，但没看到问题本质。

本质在于，要去分析这个领域缺少的是什么？第一性原理是什么？

Scaling law为什么能成为第一性原理？你只要能找到一个结构，满足两个条件：一是足够通用，二是可规模化。通用是你把所有问题放到这个框架建模，可规模化是只要你投入足够多算力，它就能变好。

这是我在Google学到的思维：如果能被更底层的东西解释，就不应该在上层过度雕花。有一句重要的话我很认同：如果你能用scale解决的问题，就不要用新的算法解决。新算法最大价值是让它怎么更好的scale。当你把自己从雕花的事中释放出来，可以看到更多。

腾讯新闻：Google那时也是scaling law的追随者吗？它是怎么贯彻第一性原理的？

杨植麟：已经有很多这样的思想，但Google没有贯彻得非常好。它有这样的思维，但它没办法组织起来，变成一个真正的moonshot（登月计划）。更多是，这有5个人追求我的第一性原理，那有5个人追求他们的第一性原理。没有top-down（自上而下）的东西。

腾讯新闻：你读博期间，先后和图灵奖得主Yann LeCun（杨立昆）、Yoshua Bengio合作发表论文，而且你都是一作。学术上这些合作是怎么产生的？——我的意思是，他们是图灵奖得主，又不是你的导师，你靠什么吸引他们？

杨植麟：学术界很open。只要你有好的想法、有意义的问题，这个都还好。两个脑子或n个脑子做出来的，比一个脑子多。这在开发AGI的时候也可以用。AI一个重要策略叫“ensemble”（使用集成方法，用多个不同的模型或方法，将它们的预测或结果结合起来，获得更优性能），本质在做一样的事情，当你有diverse的观点你可以碰撞出很多新东西。合作有很大受益。

腾讯新闻：你是先有一个idea，拿去问他们是否感兴趣吗？

杨植麟：差不多是这个过程。

腾讯新闻：在学术上搞定学术大佬和在融资中搞定资本大佬哪个更难？相似点是什么？

杨植麟：“搞定”不是一个好的词，背后本质是合作。合作就是能双赢，因为双赢是合作的前提。所以也没什么区别，需要给别人提供独特价值。

腾讯新闻：怎么让他们信任？你觉得你的天赋是什么？

杨植麟：也没有什么天赋，就是努力干活。 
#+END_QUOTE\
** 📌 [[2024-03-06]]
#+BEGIN_QUOTE
03 旧系统不适用了 —— “AGI需要新的组织方式”

腾讯新闻：你刚说“更多有价值的突破会发生在工业界”，包括创业公司、巨头的AI lab？

杨植麟：Lab是历史了。以前Google Brain是产业界最大AI lab，但它是把研究型组织安插在大公司。这种组织能探索新想法，很难产生伟大系统——能产生Transformer，但产生不了ChatGPT。

现在的开发方式会演变成，你是要做一个巨大的系统，需要新的算法，扎实的工程，甚至很多产品和商业化。好比21世纪初，你不可能在实验室研究信息检索，要放在现实世界，有一个巨大的系统，有一个有用户的产品，像Google。所以，科研或教育系统会转变职能，变成培养人才为主。

腾讯新闻：你会怎么形容这个新的系统形式？OpenAI是它的雏形？

杨植麟：它是现在最成熟的组织了，还在逐渐演化。

腾讯新闻：可以理解，这是为人类宏伟的科学目标而设立的组织？

杨植麟：我想强调，它不是纯科学，它是科学、工程和商业的结合。它得是一个商业化组织，是公司、不是研究院。但这个公司是从零到一建造的，因为AGI需要新的组织方式——一，生产方式跟互联网不一样；二，它会从纯研究变成研究、工程、产品、商业相结合。

核心是，它应该是一个登月计划，有很多自顶向下的规划，但规划中又有创新空间，并不是所有技术都确定。在一个top-down（自上而下）框架下有bottom-up（自下而上）的元素。本来不存在这样的组织，但组织要适配技术，因为技术决定了生产方式，不匹配就没法有效产出。我们相信大概率要重新设计。

腾讯新闻：去年OpenAI政变时，Sam Altman有一种选择是加入微软，领导新的微软人工智能团队。这和他在OpenAI做CEO的本质差别是什么？

杨植麟：你需要在旧文化里产生新组织，难度很大。

腾讯新闻：你想做“中国的OpenAI”，可以这么说？

杨植麟：不大准确，我们不想做中国的什么东西，也不一定想做OpenAI。

首先，真正AGI肯定是全球化的，不存在由于市场保护机制导致你只能做某个regional market（区域市场）的AGI公司，长期不存在——全球化、AGI和你有一个很大用户量的产品，这三个东西最终是必要条件。

第二，是不是OpenAI？你去看2017年-2018年，OpenAI风评很差，我们圈子的人找工作，一般考虑像Google。很多人跟Ilya Sutskever（OpenAI首席科学家）聊完，觉得这个人疯了，太自以为是了——OpenAI不是疯子就是骗子。但他们从很早开始投入，找到非共识，找到AI现在唯一work的第一性原理：通过next token prediction去scale（通过对下一个标记的预测来进行规模化）。

我认为，会有比OpenAI更伟大的公司存在。一个真正伟大的公司能结合技术理想主义，并让它用一个伟大的产品跟用户共创，AGI最终会是一个跟所有用户co-work（协作）产生的东西。所以，不光是技术，也需要功利主义和现实追求。最终在这两者之间完美结合。

不过我们应该学习OpenAI的技术理想主义。如果所有人都觉得你正常，你的理想是大家都能想到的，它对人类的理想总量没有增量。 
#+END_QUOTE\
** 📌 [[2024-03-06]]
#+BEGIN_QUOTE
04登月第一步是“长文本”，第二步呢？
“接下来会有两个大的milestone”

腾讯新闻：话题回到你决定创业的时刻，你回国后立马启动了第一轮融资？

杨植麟：（去年）2月在美国就开始了，也有远程的。最后以国内投资人为主。

腾讯新闻：第一轮融了1亿美金？

杨植麟：第一轮还没有，后来超过这个数。2023年完成两轮，总共近20亿人民币。

现在是第三轮。融资我们没有正式announce，现在没办法comment。

腾讯新闻：有人说，2023年下半年开始，已经没有人愿意投基础大模型公司了，他们说的是错误的？

杨植麟：还是有。确实能看到情绪变化，不是说没人投，至少目前市场上投资意向是蛮多的。

腾讯新闻：除了资本和人，你在2023年还做了哪些关键决策？

杨植麟：要做什么事。这是我们这类公司的优势——在最高层面的决策有技术vision（愿景）。

我们做long context（长上下文），需要对未来有判断，你要知道什么是根本的、接下来的方向。还是第一性原理，“去雕花的过程”。如果你专注雕花，只能看OpenAI已经做了什么，我看怎么把它已经做的做出来。

你会发现在Kimi（AI智能助手）里做长文本无损压缩，产品体验独特。读英语文献，它能很好帮你理解。你今天用Claude或GPT-4，不一定做得好，需要提前布局。我们做了半年多。相比我今天看到一个long context风口，赶紧召集两个团队，用最快速度开发，有很大区别。

当然马拉松刚开始，接下来会有更多差异化，这需要你提前预判到底什么是“成立的非共识”。

腾讯新闻：做这件事是在几月份决定的？

杨植麟：二三月，公司成立就决定了。

腾讯新闻：为什么长文本是登月第一步？

杨植麟：它很本质。它是新的计算机内存。

老的计算机内存，在过去几十年涨了好几个数量级，一样的事会发生在新的计算机上。它能解决很多现在的问题。比如，现在多模态架构还需要tokenizer（标记器），但当你有一个无损压缩的long context就不需要了，可以把原始的放进去。进一步讲，它是把新计算范式变成更通用的基础。

旧的计算机可以0、1表示所有，所有东西可被数字化。但今天新计算机还不行，context不够多，没那么通用。要变成通用的世界模型，是需要long context的。

第二，能够做到个性化。AI最核心的价值是个性化互动，价值落脚点还是个性化，AGI会比上一代推荐引擎更加个性化。

但个性化过程不是通过微调实现，而是它能支持很长的context（上下文）。你跟机器所有的历史都是context，这个context定义了个性化过程，而且无法被复刻，它会是更直接的对话，对话产生信息。

腾讯新闻：接下来它有多大可扩展的空间？

杨植麟：非常大。一方面是本身窗口的提升，有很长路要走，会有几个数量级。

另一方面是，你不能只提升窗口，不能只看数字，今天是几百万还是多少亿的窗口没有意义。你要看它在这个窗口下能实现的推理能力、the faithfulness的能力（对原始信息的忠实度）、the instruction following的能力（遵循指令的能力）——不应该只追求单一指标，而是结合指标和能力。

如果这两个维度持续提升，能做非常多事。可能可以follow（执行）一个几万字的instruction（指令），instruction本身会定义很多agent（智能体），高度个性化。

腾讯新闻：做长文本和追赶GPT-4技术是可复用的吗？他们是一件事吗？

杨植麟：我觉得不是。更多是升维，是一个新维度，是GPT-4没有的维度。

腾讯新闻：很多人说国内这几家大模型公司做的事都差不多——2023年追赶GPT-3.5，2024年追赶GPT-4。你认可这种说法吗？

杨植麟：综合能力提升肯定有关键目标，这个说法一定程度上是对的，你是后发肯定有追赶过程。但同时它是片面的。除了综合能力，在很多空间可以产生独特的能力，能在一些方向做到state of the art（世界领先）。Long context是一个。DALL-E3图片生成效果完败于Midjourney V6。所以要做两方面。

腾讯新闻：综合能力和新维度分别耗费的时间及生产资源，占多大比例？

杨植麟：需要结合，新维度不可能脱离综合能力存在，很难直接给出一个比例。但需要足够投入才能把新维度做好。

腾讯新闻：这些新维度对于你们，都会承载在Kimi上？

杨植麟：这肯定是我们很重要的产品，也会有一些别的尝试。

腾讯新闻：怎么看李广密（拾象创始人）说，中国大模型公司今天的技术辨识度还不算太高？

杨植麟：我觉得还好啊，我们今天只是做出了很多差异化。这跟时间有关系，今年应该能看到更多维度。去年大家是先搭个架子，先跑起来。

腾讯新闻：登月的第一步是长文本，第二步是什么？

杨植麟：接下来会有两个大的milestone（里程碑）。一是真正的统一的世界模型，就是它能统一各种不同模态，一个真正的scalable和general的architecture（可扩展、通用的系统结构）。

二是能在没有人类数据输入的情况下，使AI持续进化。

腾讯新闻：这两个milestone需要多久达到？

杨植麟：两到三年，有可能更快。

腾讯新闻：所以三年后我们已经看到的是和今天完全不一样的世界了。

杨植麟：按照今天的发展速度是这样。现在技术是萌芽，快速发展的阶段。

腾讯新闻：能不能畅想一下三年后会出现什么？

杨植麟：会有一定程度的AGI。我们今天在做的很多事AI也能做，甚至它做得更好。但关键看我们怎么用它。

腾讯新闻：对于你、对于月之暗面这家公司来说呢？接下来第二步是什么？

杨植麟：我们会去做这两件事。剩下很多问题，都是这两个因素推导出来的。今天谈到reasoning（推理）、agent（智能体），都是这两个问题解决后的产物。要再做一些雕花，但没有fundamental的blocker（根本性阻碍因素）。

腾讯新闻：你会all in追赶GPT-4吗？

杨植麟：（GPT-4）是AGI的必经之路。核心是，不能只满足做到GPT-4的效果。一是要想现在真正的非共识是什么，除了GPT-4，下一步是什么？GPT-5和GPT-6应该是什么样？二是看，你在这里面有哪些独特能力，这点更重要。

腾讯新闻：其他大模型公司会公布自己的模型能力和排名，你们好像没做这件事？

杨植麟：刷榜意义很小了。最好的榜就是用户，应该让用户投票。很多榜存在问题。

腾讯新闻：在中国大模型公司的竞赛中最快达到GPT-4，是你的目标吗？快与慢有区别吗？

杨植麟：肯定有，如果把时间放到足够长周期，最终所有人都能达到。但要看你早晚是多长周期。半年或以上的周期是有意义的，也取决于你能用这个周期做什么事。

腾讯新闻：你们预计会在什么时间达到GPT-4？

杨植麟：应该会很快，具体时间还没办法对外说。

腾讯新闻：你们会是最快的吗？

杨植麟：这要动态去看，但我们有概率。

腾讯新闻：推出Kimi之后，你的北极星指标是什么？

杨植麟：今天是把产品做得更好，有更多升维（即新的维度）。举个例子，不应该只去卷一个搜索场景，搜索在后面只是这个产品有价值的很小一部分，这个产品应该有更大增量。比传统搜索引擎好个10%、20%，没什么太大价值——只有一个颠覆性的东西，才配得上AGI这三个字。

独特价值是你增量的智能。要抓住这个点，智能永远是最核心的增量价值。如果你这个产品最核心价值只有10%-20%来自于AI，就不成立。<img src='https://pbs.twimg.com/media/GHj1AYWWwAA8IIb.jpg'/> 
#+END_QUOTE\
** 📌 [[2024-03-06]]
#+BEGIN_QUOTE
05 我一点也不焦虑落地 —— “user scaling和model scaling需要同时做”

腾讯新闻：2023年中是一个巨大分水岭，市场从狂热迅速转冷。你的感知是怎样的？

杨植麟：这个判断我不完全认同，我们确实在下半年完成了一轮融资。而且，持续有新东西出来。今天的模型能力在去年底无法想象。越来越多AI公司的用户量和revenue（收入）一直在上升。它持续地证明了价值。

腾讯新闻：上半年和下半年对于你来说，不同感受是？

杨植麟：没有太大变化，变量肯定存在，但回到第一性原理——怎么给用户提供好产品。最终，我们要满足用户需求，而不是赢得一场比赛。我们不是为了竞争而建立的公司。

腾讯新闻：业界认为，2023年上半年和下半年一个显著区别是，关注重心变了。上半年提AGI更多，下半年开始讲怎么落地、怎么商业化。你有没有这么做？

杨植麟：我肯定要做AGI嘛，这是接下来十年唯一有意义的事。但不是说我们不做应用。或者，不应该把它定义成一个“应用”。

“应用”听起来好像你有一个技术，你想把它用在什么地方，有商业化闭环。但“应用”不是准确的词。它跟AGI是相辅相成的。它本身是实现AGI的手段，也是实现AGI的目的。“应用”听起来更像目的：我为了让它有用。你是要combine东西方的哲学，要赚钱，也要有理想。

今天用户帮我们发现了很多从没考虑过的场景。他拿这个筛选简历，这是我们设计产品时没想过的，但它天然work。用户的输入反过来让模型变得更好。Midjourney为什么效果好？它在用户端做了scaling——user scaling和model scaling需要同时做。反过来，你如果只关注应用，不关注模型能力迭代，不关注AGI，贡献也有限。

腾讯新闻：朱啸虎（金沙江创投主管合伙人）就只投大模型的应用。他有一个观点：核心最难的是AIGC的PMF——你十个人找不到PMF，你投一百个人也找不到，和人数、和成本没关系，不要砸钱。他说“用LLaMA训练两三个月，至少能做到人类top 30的水平，立马可以取代人”。你怎么看他的观点？

杨植麟：AI不是我在接下来一两年找到什么PMF，而是接下来十到二十年如何改变世界——这是两种不同思维。

我们是坚定的长期主义者。当你实现AGI或更强智能，今天的一切会被改写。PMF固然重要，但如果着急找PMF，你很可能又被降维打击。降维打击发生过太多次。以前很多人做客服、对话系统，做slot filling（槽填充），有些规模不错的公司。但是，全是降维打击了，很难受。

它不是说不成立。假设你今天找到一个场景，用现在的技术能力，且从0到1增量价值巨大，从1到n空间又没那么大，这种场景OK。Midjourney就是，或者做文案生成，相对简单一点的任务，从0到1效果又很明显。这种是只关注应用的机会。但是，最大机会不在这。你的目的假设是商业化，你不可能脱离AGI去思考。我现在只做应用，那好，可能过一年你就被碾压了。

腾讯新闻：可以偷偷把底层模型升级啊。

杨植麟：但这个不可能做得比它更大。技术是这个时代唯一新变量，其他变量没变。回到第一性原理，AGI是所有事情的核心。基于这个，我们推导出来：超级应用肯定需要有最强的技术能力。

腾讯新闻：可以用开源的模型吗？（最新消息是Google宣布开源模型Gemma）

杨植麟：开源落后于闭源，这也是个事实。

腾讯新闻：会不会只是暂时落后？

杨植麟：目前看起来不是。

腾讯新闻：为什么开源追不上闭源？

杨植麟：因为开源的开发方式跟以前不一样了，以前是所有人都可以contribute（贡献）到开源，现在开源本身还是中心化的。开源的贡献可能很多都没有经过算力验证。闭源会有人才聚集和资本聚集，最后一定是闭源更好，是一个consolidation（对市场的整合）。

如果我今天有一个领先的模型，开源出来，大概率不合理。反而是落后者可能会这么做，或者开源小模型，搅局嘛，反正不开源也没价值。

腾讯新闻：你怎么对抗国内的焦虑情绪？他们会说，大模型公司如果没有快速做出能兑现投资人预期的落地场景和产品，难以融到下一笔钱。

杨植麟：需要有长期和短期的平衡。完全没有用户、没有收入，肯定不行。

可以看到，从GPT-3.5到GPT-4，解锁了很多应用；从GPT-4到GPT-4.5再到GPT-5，大概率会持续解锁更多，甚至是指数型的应用。所谓“场景摩尔定律”，就是你能用的场景数量会随着时间指数级上升。我们需要边提升模型能力，边找更多场景，需要这样的平衡。

它是个螺旋。看你投入多少分配在短期，多少分配在长期。要在你能活下去的情况下，追求长期。长期一定不能没有，否则你会错过整个时代。今天下结论，确实太早了。

腾讯新闻：你认可王慧文（美团联合创始人、光年之外创始人）提出的“双轮驱动”吗？

杨植麟：这是个好问题。一定程度上是这个逻辑。但你真正怎么去做，有很大区别。是不是能真的做一些“有概率的非共识”？

腾讯新闻：我理解他们说的双轮驱动，也需要快速找到那个新的应用场景，否则不知道技术何以落地。

杨植麟：还是model scaling（模型扩展）和user scaling（用户扩展）之间的区别。

腾讯新闻：国内除了你是model scaling的思维，还有谁是？

杨植麟：这个我就不好评价了。

腾讯新闻：大多数人可能是user scaling的思维。或者能不能这么说，这是学院派和商业落地派的区别？

杨植麟：我们不是学院派，学院派绝对不work。

腾讯新闻：很多大模型公司会通过to B落地（毕竟to B的确定性高），你们做吗？

杨植麟：我们不做。我们从第一天就决定做to C。

看你要什么东西。如果你知道这不是你想要的，你就不会FOMO。因为得到了，也没啥。

腾讯新闻：你焦虑吗？过去一年。

杨植麟：更多是兴奋、激动。因为这件事我想了非常久。我们可能是我们最早想去探索月之暗面的人。你今天发现你真的在造一架火箭，每天在讨论往火箭里加什么燃料跑得更快，怎么样不让它炸了。

腾讯新闻：总结一下你所做过的“有概率的非共识”决定，除了to C、长文本，还有吗？

杨植麟：更多在过程中，希望尽快跟大家见面。

腾讯新闻：中国上一代创业者在应用和场景上吃到甜头，所以他们更看产品、用户、数据飞轮。以你为代表的新一代AI创业者，能代表新的未来吗？

杨植麟：我们也很关注用户，用户是我们最终的目标，但也是共创的过程。最大区别是，这次会更加技术驱动——还是那个马车和汽车的问题——现在属于从马车到汽车的跳跃过程，应该尽可能想怎么给用户提供一辆汽车。

腾讯新闻：你会觉得孤独吗？

杨植麟：哈哈哈……你这个问题很有意思。我觉得还好，因为我们还有大几十、100号人一起在战斗。 
#+END_QUOTE\
** 📌 [[2024-03-06]]
#+BEGIN_QUOTE
06 GPT-4还没赶上，Sora又来了 —— “现在就有点像视频生成的GPT-3.5”

腾讯新闻：今年Sora的突然出现，多少在你的意料之中，多少在你的意料之外？

杨植麟：Generative AI（生成式AI）做到这个效果，在意料之内，意外的是时间——比之前预估更早。这也反映了现在AI的发展很快，很多scaling的红利没有被完全吃下来。

腾讯新闻：去年业界就判断，2024年大模型一定会卷多模态叙事，视频的生成效果会像2023年文生图一样迅速提升。Sora的技术能力是超出、符合还是低于你的预期？

杨植麟：解决了很多之前比较难的问题。比如，能在一个比较长的时间窗口内保持生成的一致性，这是关键点，是一个巨大的提升。

腾讯新闻：它对于全球产业格局来说意义是什么？2024年大模型会有哪些新叙事？

杨植麟：一是短期的应用价值，可以在生产环节进一步提升效率，当然更期待在目前能力基础上，有更多延展。二是和其他模态结合。它本身是对世界建模，有了这个知识，对现有文本是非常好的补充。在这个基础上，不管在agent还是和物理世界的连接方面，有蛮多空间和机会。

腾讯新闻：你们总体怎么判断Sora？

杨植麟：我们本来也在筹划类似方向，做了一段时间。方向上，倒没有太大意外，更多是技术细节。

腾讯新闻：应该学习的技术细节是？

杨植麟：很多OpenAI也没完全讲清楚。它讲了大致的，会有一些关键细节。这要从它的效果或已有信息再去判断，也结合我们之前的实验。至少对我们来说，在开发过程中会加上更多数据点，有更多数据输入。

腾讯新闻：之前视频生成相对文字生成来说，主要瓶颈有哪？这次可以看到OpenAI找到了哪些解决办法？

杨植麟：主要瓶颈，核心还是数据，你怎么去规模化地拟合这个数据？之前没被验证过。特别是，当你的动作比较复杂，生成的效果photo realistic（照片逼真）。在这样的条件下，能够去规模化，它这次解决了这些。

剩下的是它也没有完全解决，比如需要一个统一的architecture（架构）。DiT这个architecture仍然不是非常通用。在单纯对视觉信号的marginal probability（边际概率）去建模，它可以做得非常好，但怎么泛化成一个通用的新计算机？还是需要更unified architecture（统一的架构），这个东西还是有空间。

腾讯新闻：你读了OpenAI出的Sora报告没有？《Video generation models as world simulators》，里面有什么关键点值得划重点？

杨植麟：读了。考虑到当前的竞争情况，最重点它肯定都不会写出来。但还是值得学习，这个东西本来是付费内容，你可能要花钱做很多实验才知道，但现在你知道的有一些东西，不用花钱做实验，就大概有一个认知吧。

腾讯新闻：你从里面提取到的关键信号是？

杨植麟：这个东西一定程度上是scalable的。此外，它也给出了比较具体的architecture到底怎么做。但也有可能不同architecture在这个事情上不一定有那么本质的区别。

腾讯新闻：你认可它那句话吗？——“扩展视频生成模型是构建物理世界通用模拟器的一条有前途的途径。”

杨植麟：我非常认同，这两个东西优化的是同一个目标函数，没有太大疑问。

腾讯新闻：你怎么看杨立昆又跳出来反对生成式AI？他的观点是：“通过生成像素对世界进行建模是一种浪费，并且注定会失败。生成恰好适用文本，因为文本是离散的具有有限数量的符号。这种情况下，处理预测中的不确定性很容易，处理高纬连续感官输入中的预测不确定性是非常棘手的。”

杨植麟：我现在觉得，你通过对视频的边际概率去建模，本质是在做无损压缩，跟语言模型next token predictions没有本质区别。只要你压缩得足够好，就可以把这个世界可以被解释的东西去进行解释。

但同时也有重要的还没做的事：它怎么跟已有的已经被压缩的能力结合起来？

可以理解成有两种不同压缩。一种是压缩原始世界，这是视频模型在做的。另一种是压缩人类产生的行为，因为人类产生的行为经过了人的大脑，这是世界上唯一能产生智能的东西。你可以认为视频模型在做第一种，文本模型在做第二种，当然视频模型也一定程度包含了第二种，一些人创造出来的视频包含了创作者的智能。

它最终可能会是mix，需要通过这两种方式从不同角度学习，但最终对智能的增长都有帮助。

所以，生成可能不是目的，它只是压缩这个函数。如果你压缩足够好，最后生成的效果就会很好。反过来，如果你这个模型本身没办法生成，是不是也存在可能把它压缩得非常好？这点存疑。有可能生成非常好，是压缩非常好的一个必要条件。

腾讯新闻：Sora相对于去年的ChatGPT来说，是两个不一样的milestone，哪个更重大？

杨植麟：都很重要。现在就有点像（视频生成的）GPT-3.5，是阶跃式提升。它的模型也还比较小，可预见的是会有更大的模型，是确定性的效果提升。

腾讯新闻：也有人评价说，对于做多模态，Google Gemini突破更重要一些。

杨植麟：Gemini是follow GPT-4V的路线，把这个理解也放进去了。都很重要，只是最终需要把这些东西放在同一个模型，这还没解决。

腾讯新闻：为什么放在同一个模型那么难？

杨植麟：大家还不知道怎么做，还不存在一个被验证过的architecture。

腾讯新闻：Sora + GPT会产生什么？

杨植麟：Sora马上可以用到视频生产过程中，但如果跟语言模型结合，就有可能打通数字世界和物理世界。另外，你也可以去更加端到端完成任务，因为现在你对这个世界的建模比之前更好，它甚至能用来提升你对多模态输入的理解能力。所以你最后能在不同模态之间做比较多切换。

总结下来，你对世界的理解更好了，你可以在数字世界里做更加端到端的任务，甚至去架起一座桥梁，连接物理世界，完成一些物理世界里的任务。这是起点。比方说，自动驾驶，或者一些家务，理论上都是打通物理世界的一个概念。

所以数字世界的突破是确定的了，但它也还是潜在有通往物理的可能。

腾讯新闻：Sora对国产大模型公司意味着什么？有什么应对策略？

杨植麟：没什么区别，这本来就是确定性方向。

腾讯新闻：国产大模型GPT-4还没赶上，Sora又来了，你怎么看？两个世界好像差得越来越远，你感觉焦虑吗？

杨植麟：这就是客观的事实嘛。但实际上的差距可能还在缩小，这是技术发展的规律。

腾讯新闻：什么意思？就是说，一开始技术曲线很陡峭，接着慢慢放缓。

杨植麟：是的。我倒没有很意外，OpenAI一直在做下一代模型。但客观上差距会持续存在一段时间，甚至在国内不同公司之间的差距也会持续一段时间，现在是技术爆发期。

但再过两三年，有可能中国顶尖的公司可以在这里面去做好更多基础性工作，包括技术的基建、人才的储备和组织文化的沉淀，有这些打磨后，更有可能在某一些方面有领先可能性——但需要一定的耐心。

腾讯新闻：中美最终有没有可能形成的是完全不一样的AI科技生态？

杨植麟：生态有可能不一样，如果你是从产品和商业化角度。但从技术角度，通用能力不会是完全不同的技术路线，基础通用能力肯定会差不多。但因为AGI空间很大，在通用能力基础上去有差异化，这个更可能发生。

腾讯新闻：硅谷一直有一个争论：one model rules all还是many specialized (smaller) models（一个通用模型来处理各种任务，还是采用许多专门的较小模型来处理特定任务），你怎么看？

杨植麟：我的观点是第一个。

杨植麟：在这一点上，中美会呈现巨大不同吗？

杨植麟：我觉得最终不会。 
#+END_QUOTE\
** 📌 [[2024-03-06]]
#+BEGIN_QUOTE
07 我接受有失败的概率 —— “它已经改变了我的生命”

腾讯新闻：大模型创业在中国是比较怪异的存在，你们融了这么多钱，但似乎一大笔钱都要花在做科学实验上，这种情况下怎么说服投资人愿意掏钱？

杨植麟：跟在美国没有区别。我们今天拿到的钱还不算特别多。所以，我们还要更多向OpenAI学习。

腾讯新闻：我想知道做到GPT-4还需要多少钱？做到Sora还需要多少钱？

杨植麟：GPT-4和Sora都不需要那么多，现在的钱更多是为了下一代甚至下下代模型做储备，做前沿探索。

腾讯新闻：中国大模型创业公司虽然拿了巨头的钱，但巨头也在训练自己的模型——你怎么看大模型创业公司和巨头的关系？

杨植麟：这里面有竞争，也有合作。巨头和创业公司第一目标不一样，今天你去看每个大厂的第一目标，跟AGI公司的第一目标不同。第一目标会影响动作、结果，最终在生态里是不同的关系。

腾讯新闻：为什么巨头同时对多家大模型公司投入一点钱，而不重注一家公司？

杨植麟：这是阶段问题。下面会有更多的consolidation（资源整合），会有更少的公司。

腾讯新闻：有人说大模型公司的终局是被巨头收购，你认可吗？

杨植麟：我觉得不一定，但是他们有可能有很深入合作关系。

腾讯新闻：比如说，可以怎么合作？

杨植麟：OpenAI和微软就是典型合作模式，这里面很多可以参考，也有一些可以优化。

腾讯新闻：过去一年，在你看来创业中的曲折体现在了哪？

杨植麟：外部变量很多——资本、人才、卡、产品、研发、技术。有高光时刻，也有困难要克服。比如说卡。

中间有很多back and forth（来回）。一段时间很紧张，一段时间供应变好。最夸张的是，有一段时间每天在变，今天一台机器价格260，明天340了，过两天又跌回来，是一个动态变化的过程。要对这件事密切关注。价格一直变，策略也要一直变，到底从什么渠道，买还是租，有很多不同选择。

腾讯新闻：这个动态因素是受什么影响？

杨植麟：有geo-political（地缘政治）原因，生产本身有批次，也受市场情绪变化。我们观察到很多公司开始退卡，他们发现自己不一定要训这个模型。市场情绪和大家的决策变化，供求关系跟着变化。好消息是，最近整个市场供应好了非常多。我个人判断至少在接下来一到两年，卡不会成为很大瓶颈。

腾讯新闻：你似乎一直在思考组织，在团队构建上是怎么做的？

杨植麟：招人思路发生过一些变化。世界上AGI人才非常有限，有经验的人很少。我们最早期的画像是，专注找对口的genius（天才）。这个证明非常成功。之前有对模型动手术的能力，有训练超大规模模型直接的经验，就可以很快做出来。包括Kimi发布，资本效率和组织效率其实很高。

腾讯新闻：花了多少钱？

杨植麟：一个挺小的数，相比很多其他花费，是花小钱办大事。我们很长一段时间是30-40人的状态。现在80人。我们追求人才密度。

人才画像后来发生了变化。最早期招genius，认为他的上限高，公司上限是由人的上限决定的。但后面我们补齐了更多维度的人——产品运营侧的人，leader型的人，能把事情做到极致的人。现在是一个更完整、有韧性、能打仗的团队。

腾讯新闻：在中国大模型创业一年，怎么评价现在取得的阶段性成果？

杨植麟：造了一个火箭的原型，现在点火试飞。积累了一个团队，弄清楚了一些燃料的配方，多多少少还能看到一个PMF的雏形。

可以说，登月走了第一步。

腾讯新闻：你怎么看杨立昆说，他不看好现有技术路线，认为自监督的语言模型没办法习得真正世界的知识，随着模型规模的扩大出现谬误，也就是机器幻觉的几率会越来越高。他提出了“世界模型”的观点。

杨植麟：没有本质瓶颈。当token space足够大，变成一个新型计算机解决通用性问题就OK了，它就是一个通用世界模型。

（他这么说）很重要一点在于，大家都能看到现在的局限性。但解决方式并不一定需要全新框架。AI唯一work就是next token prediction + scaling law，只要token足够完整，都是可以做的。当然今天他指出的问题存在，但这些问题就是你把token space变得很通用，就可以了。

腾讯新闻：他是放大了局限性。

杨植麟：我觉得是。但底层第一性原理没什么问题，只是说现在有些小技术问题没解决。

腾讯新闻：你怎么看Geoffrey Hinton（深度学习之父）一而再、再而三呼吁AI Safety的问题？

杨植麟：Safety反而表明了，他对接下来技术能力的提升有极大信心。他们是相反的。

腾讯新闻：幻觉的问题怎么解决？

杨植麟：还是scaling law，就是scale的是不一样的东西。

腾讯新闻：有多大概率scaling law走到最后发现根本走不通？

杨植麟：可能约等于0。

腾讯新闻：怎么看你的CMU校友陆奇的观点：OpenAI未来肯定比Google大，只不过是大一倍、五倍还是十倍的问题？

杨植麟：未来最成功的AGI公司肯定是会比现在所有公司都大。这点没有疑问，它最终可能是double、triple GPT的事。它不一定是OpenAI，有可能是别的公司，但肯定有这样的公司。

腾讯新闻：如果你恰巧成了这家AI帝国的CEO，你会做什么用以保护人类？

杨植麟：现在想这个问题还缺少一些前提条件。但我们肯定愿意跟社会不同角色去合作和提升，包括在模型上有更多安全措施。

腾讯新闻：你2024年的目标是什么？

杨植麟：第一是技术突破，我们现在应该能做出比2023年好得多的模型。第二是用户和产品，希望有更多成规模的用户和黏性。

腾讯新闻：2024年对于全球大模型产业有哪些预测？

杨植麟：今年还会有更多capability出现，但格局不会跟今天有太大差别，top这几个还是会领先。在能力上应该今年下半年会有一些比较大的突破，很多会来自OpenAI，它肯定还有下一代模型——有可能是4.5，也有可能是5，感觉是大概率事件。视频的生成模型肯定还能继续scale。

腾讯新闻：2024年对于国产大模型产业有哪些预测？

杨植麟：一是可以看到新的独特能力产生。你会看到国产模型，因为前期的投入，有合适的团队，做出世界领先的某一些维度的能力。二是会出现更多用户量级更大的产品，这是大概率的。三是会有进一步的consolidation和路线选择的分化。

腾讯新闻：创业你最害怕的一件事情是什么？

杨植麟：还好，就是要无所（畏惧）往前冲啊。

腾讯新闻：想对同行说什么？

杨植麟：一起努力。

腾讯新闻：说一个你对于大模型行业现在还不知道但最想知道的问题。

杨植麟：我不知道AGI的上限是什么样的，它会产生一个什么样的公司，这个公司能产生出来什么样的产品。这是我现在最想知道的事。

腾讯新闻：AGI这么发展下去，你最不想看到的一件事是什么？

杨植麟：我对这个比较乐观，它可以让人类文明往下一个阶段去发展。

腾讯新闻：有没有人评价你，太过于理想主义？

杨植麟：我们也是很脚踏实地的，我们真的也做了一些事，不是只是在说嘛。

腾讯新闻：如果你今天拿到的钱是最后一笔钱，你会怎么花这笔钱？

杨植麟：我希望这个永远不会发生，因为我们未来还需要很多钱。

腾讯新闻：如果你没有做成什么，会觉得自己失败了？

杨植麟：关系不是那么大，我接受有失败的概率。

这个事情它已经完全改变了我的生命，我是充满感激的。 
#+END_QUOTE\