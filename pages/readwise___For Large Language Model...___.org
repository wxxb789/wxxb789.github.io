:PROPERTIES:
:title: readwise/For Large Language Model...
:END:

:PROPERTIES:
:author: [[luis_likes_math on Twitter]]
:full-title: "For Large Language Model..."
:category: [[tweets]]
:url: https://twitter.com/luis_likes_math/status/1621622486310739969
:image-url: https://pbs.twimg.com/profile_images/1367312511532486659/5qAetx-o.jpg
:END:

* Highlights first synced by [[Readwise]] [[2023-12-18]]
** ğŸ“Œ
#+BEGIN_QUOTE
For large language models, it is crucial to know when two words, or two sentences, are similar or different.

This can be a hard problem, but luckily, word and sentence embeddings are very helpful for this task. 

Letâ€™s see how. (Thread) 

![](https://pbs.twimg.com/media/FoEgaRZXEAg2zap.jpg) 
#+END_QUOTE
    date:: [[2023-02-04]]
*** from _For Large Language Model..._ by @luis_likes_math on Twitter
*** [View Tweet](https://twitter.com/luis_likes_math/status/1621622486310739969)
** ğŸ“Œ
#+BEGIN_QUOTE
First, a recap. Earlier we covered word embeddings â€” the assignment of a vector to every word.

Sentence embeddings, like what you get from the Cohere API, are even more powerful as they use a whole sentence as the context.

Read it here.
https://t.co/y9fQ8opV4I
@CohereAI 
#+END_QUOTE
    date:: [[2023-02-04]]
*** from _For Large Language Model..._ by @luis_likes_math on Twitter
*** [View Tweet](https://twitter.com/luis_likes_math/status/1621622489213288452)
** ğŸ“Œ
#+BEGIN_QUOTE
Now that we know about embeddings, letâ€™s move on to using them to find similarities.

There are two types of similarities weâ€™ll define in this post:
\- Dot product similarity
- Cosine similarity 
#+END_QUOTE
    date:: [[2023-02-04]]
*** from _For Large Language Model..._ by @luis_likes_math on Twitter
*** [View Tweet](https://twitter.com/luis_likes_math/status/1621622491117457411)
** ğŸ“Œ
#+BEGIN_QUOTE
1/ Dot Product Similarity
Letâ€™s start with a small example. Consider a dataset of 4 sentences, all movie titles, and an embedding of dimension 2.

Here are their embeddings:
\- Youâ€™ve Got Mail [0, 5]
- Rush Hour [6, 5]
- Rush Hour 2 [7, 4]
- Taken [7, 0] 
#+END_QUOTE
    date:: [[2023-02-04]]
*** from _For Large Language Model..._ by @luis_likes_math on Twitter
*** [View Tweet](https://twitter.com/luis_likes_math/status/1621622493034209280)
** ğŸ“Œ
#+BEGIN_QUOTE
Would these embeddings mean anything?

It could well be that the first score is the amount of action in the movie, and the second score the amount of comedy.

Hereâ€™s the table: 

![](https://pbs.twimg.com/media/FoEgysaX0AEC0-W.png) 
#+END_QUOTE
    date:: [[2023-02-04]]
*** from _For Large Language Model..._ by @luis_likes_math on Twitter
*** [View Tweet](https://twitter.com/luis_likes_math/status/1621622494586175494)
** ğŸ“Œ
#+BEGIN_QUOTE
Notice that if two movies are similar, then they must have similar action scores and similar comedy scores.

So, if we multiply the two action scores, then multiply the two comedy scores, and add them, this number would be high if the scores match. 
#+END_QUOTE
    date:: [[2023-02-04]]
*** from _For Large Language Model..._ by @luis_likes_math on Twitter
*** [View Tweet](https://twitter.com/luis_likes_math/status/1621622496758829057)
** ğŸ“Œ
#+BEGIN_QUOTE
On the other hand, if the scores donâ€™t match very well, then the similarity score would be lower.

This operation is called the dot product. 
#+END_QUOTE
    date:: [[2023-02-04]]
*** from _For Large Language Model..._ by @luis_likes_math on Twitter
*** [View Tweet](https://twitter.com/luis_likes_math/status/1621622498394607618)
** ğŸ“Œ
#+BEGIN_QUOTE
Letâ€™s see how it works for the two pairs of movies.

Dot product for the pair [Youâ€™ve Got Mail, Taken] = 0*7 + 5*0 = 0
Dot product for the pair [Rush Hour, Rush Hour 2] = 6*7 + 5*4 = 62 
#+END_QUOTE
    date:: [[2023-02-04]]
*** from _For Large Language Model..._ by @luis_likes_math on Twitter
*** [View Tweet](https://twitter.com/luis_likes_math/status/1621622500055519234)
** ğŸ“Œ
#+BEGIN_QUOTE
Letâ€™s do a real-life example with the Cohere embedding.

Consider the following three sentences:

Sentence 1: â€œI like to be in my houseâ€
Sentence 2: â€œI enjoy staying homeâ€
Sentence 3: â€œthe isotope 238u decays to 206pbâ€ 
#+END_QUOTE
    date:: [[2023-02-04]]
*** from _For Large Language Model..._ by @luis_likes_math on Twitter
*** [View Tweet](https://twitter.com/luis_likes_math/status/1621622501724880898)
** ğŸ“Œ
#+BEGIN_QUOTE
The embeddings are as follows:

Sentence 1: [-1.3662109  -0.53759766  ...  0.68408203]
Sentence 2: [-0.38427734  2.3808594 ...  0.6542969 ]
Sentence 3: [-1.3916016  -1.6757812  ... 0.17578125]

Note that these are vectors (lists) of 4096 numbers, so they are truncated here. 
#+END_QUOTE
    date:: [[2023-02-04]]
*** from _For Large Language Model..._ by @luis_likes_math on Twitter
*** [View Tweet](https://twitter.com/luis_likes_math/status/1621622503364780034)
** ğŸ“Œ
#+BEGIN_QUOTE
Letâ€™s calculate the dot products between the three sentences. 

Here are the similarity scores:

Sentences 1 and 2: 6738.2858668486715
Sentences 1 and 3: -122.22666955510499
Sentences 2 and 3: -3.494608113647928 
#+END_QUOTE
    date:: [[2023-02-04]]
*** from _For Large Language Model..._ by @luis_likes_math on Twitter
*** [View Tweet](https://twitter.com/luis_likes_math/status/1621622504983764992)
** ğŸ“Œ
#+BEGIN_QUOTE
This confirms our predictions. The similarity between sentences 1 and 2 is high. The similarities between sentences 1 and 3, and 2 and 3, are much lower.

But, wouldnâ€™t it be lovely to have a score that was, say, between 0 and 1?

Cosine similarity does precisely that. 
#+END_QUOTE
    date:: [[2023-02-04]]
*** from _For Large Language Model..._ by @luis_likes_math on Twitter
*** [View Tweet](https://twitter.com/luis_likes_math/status/1621622506640515072)
** ğŸ“Œ
#+BEGIN_QUOTE
2/ Cosine Similarity

Another measure of similarity between sentences (and words) is to look at the angle between them.

For example, letâ€™s plot the movie embeddings on a plane. 

![](https://pbs.twimg.com/media/FoEhdBTX0AAvJv5.jpg) 
#+END_QUOTE
    date:: [[2023-02-04]]
*** from _For Large Language Model..._ by @luis_likes_math on Twitter
*** [View Tweet](https://twitter.com/luis_likes_math/status/1621622508238655489)
** ğŸ“Œ
#+BEGIN_QUOTE
Letâ€™s look at the angle between the rays from the origin ([0,0]), and each sentence.

Notice that this angle is small if the points are close to each other, and large if the points are far away from each other. 
#+END_QUOTE
    date:: [[2023-02-04]]
*** from _For Large Language Model..._ by @luis_likes_math on Twitter
*** [View Tweet](https://twitter.com/luis_likes_math/status/1621622510277087232)
** ğŸ“Œ
#+BEGIN_QUOTE
Now, we need a function: the cosine. The cosine of angles close to 0 is close to 1, and as the angle grows, the cosine decreases. Exactly what we need. 

Therefore, the cosine distance is the cosine of the angle formed by the two rays going from the origin to the two sentences. 

![](https://pbs.twimg.com/media/FoEojFlXEAAwViG.jpg) 
#+END_QUOTE
    date:: [[2023-02-04]]
*** from _For Large Language Model..._ by @luis_likes_math on Twitter
*** [View Tweet](https://twitter.com/luis_likes_math/status/1621622513481682944)
** ğŸ“Œ
#+BEGIN_QUOTE
Letâ€™s calculate the cosine distance of our previous example.

Sentence 1: â€œI like to be in my houseâ€
Sentence 2: â€œI enjoy staying homeâ€
Sentence 3: â€œthe isotope 238u decays to 206pbâ€ 
#+END_QUOTE
    date:: [[2023-02-04]]
*** from _For Large Language Model..._ by @luis_likes_math on Twitter
*** [View Tweet](https://twitter.com/luis_likes_math/status/1621622515658362880)
** ğŸ“Œ
#+BEGIN_QUOTE
Here are the cosine similarity scores:

Sentences 1 and 2: 0.7739596968978093
Sentences 1 and 3: -0.014663026750986932
Sentences 2 and 3: -0.00041937178612739233 
#+END_QUOTE
    date:: [[2023-02-04]]
*** from _For Large Language Model..._ by @luis_likes_math on Twitter
*** [View Tweet](https://twitter.com/luis_likes_math/status/1621622517226930178)
** ğŸ“Œ
#+BEGIN_QUOTE
This checks out as well! The similarity between sentences 1 and 2, which are similar, is 0.77. On the other hand, their similarities with sentence 3 are very close to 0. 
#+END_QUOTE
    date:: [[2023-02-04]]
*** from _For Large Language Model..._ by @luis_likes_math on Twitter
*** [View Tweet](https://twitter.com/luis_likes_math/status/1621622518959177732)
** ğŸ“Œ
#+BEGIN_QUOTE
Similarity is a very useful concept in large language models as it can be used for search, translation, summarization, and many other tasks.

Stay tuned to learn more about these applications.

In the meantime, read the full blog for more: https://t.co/Mf7Eohiy0e 
#+END_QUOTE
    date:: [[2023-02-04]]
*** from _For Large Language Model..._ by @luis_likes_math on Twitter
*** [View Tweet](https://twitter.com/luis_likes_math/status/1621622520855072768)