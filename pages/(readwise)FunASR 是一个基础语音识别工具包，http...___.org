:PROPERTIES:
:title: (readwise)FunASR 是一个基础语音识别工具包，http...
:END:

:PROPERTIES:
:author: [[Barret_China on Twitter]]
:full-title: "FunASR 是一个基础语音识别工具包，http..."
:category: [[tweets]]
:url: https://twitter.com/Barret_China/status/1729681417137954954
:image-url: https://pbs.twimg.com/profile_images/639253390522843136/c96rrAfr.jpg
:END:

* Highlights first synced by [[Readwise]] [[2023-12-05]]
** 📌
#+BEGIN_QUOTE
FunASR 是一个基础语音识别工具包，https://t.co/dqVAIPl91v，相比 pyannote-audio 它的内容更加全面，包括了语音识别（ASR）、语音端点检测（VAD）、标点恢复、语言模型、说话人验证、说话人分离和多人对话语音识别等模块，而且提供了非常多的预训练模型，https://t.co/HoGlYlE0XW，可供推理和微调。

需要特别提到它的两个模块，一个是基于前馈顺序记忆网络（FSMN-VAD）的语音活动检测模型，另外一个是基于可控时延 Transformer（CT-Transformer），相比 OpenAI 的 Whisper 这两块能力还是比较突出的。

前者用于识别语音中的有效声音部分，过滤掉无效噪声和静音部分，可以大量减少幻觉问题；后者用于在生成的文本中添加标点符号和去除语气停顿等不流畅的部分，它的原理是通过实时进行标点预测和语气停顿检测，将标点符号和语气停顿插入到识别文本中的适当位置。另外，参与这些模型训练的数据质量非常高，都是有人工标注且数据量庞大（6w+ 小时）的工业数据。

从 Whisper 论文的一张图中看到，数据集体量和词错率是呈负相关的，Whisper 用了 68w 小时的数据，从这个角度来看，FunASR 不会有太大的优势。只不过 Whisper 参与训练的中文数据占比并不高，而且中英文训练本身也存在一定的差异，因此 FunASR 的中文效果有可能会比 Whisper 更优秀。

当前 FunASR 大部分模块还只支持 CPU 推理，GPU 兼容还在建设中，因此它的一个特点就是慢，https://t.co/qqRFVg9AUW，这篇文章提到，Whisper 4s 能搞定的事儿，交给 FunASR 需要 33s，不过优势也较为显著，FunASR 的标点符号清晰，而且准确率很高。

我翻了一下 FunASR 的 Github issues，https://t.co/9TWhg5L2vz，Bug 量还是挺大的，当然，这无可厚非，毕竟还是一个比较新的产品，距离走向成熟还需要一段时间；Bug 集中在内存回收和时间戳不准等几个问题上，都是能让使用者头疼的问题点。如果你对中文语音识别有强烈诉求，可以考虑围观下，也可以尝鲜试一试。<img src='https://pbs.twimg.com/media/GAENuSaa0AArAtj.jpg'/> 
#+END_QUOTE
    date:: [[2023-11-29]]
*** from _FunASR 是一个基础语音识别工具包，http..._ by @Barret_China on Twitter
*** [View Tweet](https://twitter.com/Barret_China/status/1729681417137954954)