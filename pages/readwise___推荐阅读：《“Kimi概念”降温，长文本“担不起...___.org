:PROPERTIES:
:title: readwise/推荐阅读：《“Kimi概念”降温，长文本“担不起...
:END:


* metadata
:PROPERTIES:
:author: [[dotey on Twitter]]
:full-title: "推荐阅读：《“Kimi概念”降温，长文本“担不起..."
:category: [[tweets]]
:url: https://twitter.com/dotey/status/1773042696849924386
:image-url: https://pbs.twimg.com/profile_images/561086911561736192/6_g58vEs.jpeg
:END:

* Highlights first synced by [[Readwise]] [[2024-04-08]]
** 📌 [[2024-03-28]]
#+BEGIN_QUOTE
推荐阅读：《“Kimi概念”降温，长文本“担不起”大模型的下一步》

https://t.co/n0bneysDuk

部分内容摘录：

kimi选择了一个更有辨识度的方式亮相。2023年10月10日，月之暗面的官方公众号发布kimi的上线官宣文章，标题中别有心裁地用了“欢迎与Moonshot AI共同开启Looooooooooong LLM时代”，"long"这个单词中间，特地敲入了十个“o"，long一下子变得视觉可见的长。而公众号的第一句就是“今天，Moonshot AI 带着首个支持输入 20 万汉字的智能助手产品Kimi Chat 与大家见面了”。

所有的宣发内容，用户一眼就能记住一个词“长文本”。月之暗面是懂营销的，直接占领用户心智。从此，用户看到“长文本”，只能想到“月之暗面”。

月之暗面的目标是C端，为了让C端用户能够理解“长文本”这个技术名词，杨植麟用了更形象的比喻“支持更长的上下文”意味着大模型拥有更大的“内存”。这个世界已经被计算机、手机教育过了，每个普通人都有一个“简单粗暴”的认知，“内存大”就意味着这个手机或电脑配置更高、性能更牛、价格也更贵。

一波漂亮的宣传，在“卷评测分数”的大模型界轻松地赢得了普通用户的心。

在后续的重要宣发中，月之暗面不断重复kimi的长文本能力，创始人杨植麟也在采访中强调“为什么长文本是登月第一步？它很本质。它是新的计算机内存。”

早在20世纪60年代，艾·里斯与杰克·特劳特就提出了经典的《定位》理论，它的核心概念在于将品牌建设的焦点从产品本身转移到潜在客户的心理认知上。在定位理论中，占领用户心智意味着在目标消费者心中为品牌或产品创造一个独特、明确且吸引人的位置。这样，当消费者考虑购买某一类产品或服务时，你的品牌能够成为他们首先想到的选择。

当用户认为在国内的大模型中，长文本=kimi的时候，除非竞争对手能以绝对的实力碾压几个量级，但凡与kimi打平或者是微弱超越，都很难威胁到kimi在用户心目中的地位。即使是如百度、阿里等科技大厂也宣布开放长文本能力，似乎也丝毫没有影响到kimi的热度。

而且，kimi只有一个，在资本市场上，可以享受泡沫，但是当退潮的时候，还是要保持一分清醒。

![](https://pbs.twimg.com/media/GJscqpIWYAAizit.jpg) 
#+END_QUOTE\
** 📌 [[2024-03-28]]
#+BEGIN_QUOTE
早在Kimi引发国内大模型“长文本马拉松竞赛”的4个月前，美国大模型界就已经赛过一轮了。参赛的两名选手是OpenAI的GPT4-Turbo和Antrophric的Claude。在去年11月，OpenAI在Dev Day上发布了GPT4-Turbo， 最高支持128k上下文长度的输入，这一下打到了Claude的命门。在能力全面落后GPT4的基础上，唯一的优势也被超越，Antrophric顿时陷入了危机。在14天后，Antrophric紧急发布Claude 2.1，在其他能力没有显著增强的情况下，仅把上下文支持从100k提升到了200k来应对挑战。而在今年2月发布的Geminni 1.5更是直接把上下文窗口推到了100万的水位，这基本上是哈利波特全集的长度和1小时视频的量级。

这说明全球第一梯队的三个大模型，在去年都突破了长文本的限制。

这其中还有一个小插曲，Claude 2.1发布后，完全没想到行业人士这么快就对它进行了探针测试，可以用简单的概念来理解，就是大海捞针。

探针测试的逻辑是向长文章的不同位置中注入一些和文章完全不相关的话语，看它能不能找出来。能就说明它真的懂了，不能就说明它只是支持了这样的长度，但并没有记住。Claude 2.1探针综合召回率只有20%，可以说基本没记住，而对比GPT4 Turbo放出的论文中，128k长文本的召回率足有97%。

在这场公关战中落于下风的Claude紧急打了补丁，在12月6日放出更新，探针召回率大幅提升，而且按Antrophic官方的说法，他们只是加了个Prompt就解决了这个问题。

（官方文档：通过在克劳德的回答开头添加“这是上下文中最相关的句子：”这句话，我们在相同的评估中取得了明显更好的结果。）

（探针实验效果效果前后对比）

一个Prompt就能解决上下文拓展中出现的严重问题。如果不是Claude 本身在故意隐藏底牌，只能说到了12月份，这个护城河已经略浅了。

而到了3月份，中文大模型的这场最新版本的长文本战争时，其他厂商的快速跟上，更为“护城河略浅”加了些注脚。

![](https://pbs.twimg.com/media/GJsdp-gWwAAEJTn.jpg)

![](https://pbs.twimg.com/media/GJsdsqIXAAAkZz9.jpg) 
#+END_QUOTE\
** 📌 [[2024-03-28]]
#+BEGIN_QUOTE
https://t.co/flTmHxmT5T 
#+END_QUOTE\