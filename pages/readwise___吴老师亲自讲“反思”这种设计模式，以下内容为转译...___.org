:PROPERTIES:
:title: readwise/吴老师亲自讲“反思”这种设计模式，以下内容为转译...
:END:


* metadata
:PROPERTIES:
:author: [[dotey on Twitter]]
:full-title: "吴老师亲自讲“反思”这种设计模式，以下内容为转译..."
:category: [[tweets]]
:url: https://twitter.com/dotey/status/1773491116647576059
:image-url: https://pbs.twimg.com/profile_images/561086911561736192/6_g58vEs.jpeg
:END:

* Highlights first synced by [[Readwise]] [[2024-04-08]]
** 📌 [[2024-03-29]]
#+BEGIN_QUOTE
吴老师亲自讲“反思”这种设计模式，以下内容为转译

上周，我介绍了四种AI智能体工作流程的设计模式，我认为它们今年将大大推进技术进步：反思、工具使用、规划以及多智能体协作。不同于让一个大语言模型直接输出最终结果，智能体工作流程通过多次提示LLM，使其有机会逐步提高输出质量。此次，我想重点讲讲“反思”这一模式。它相对易于实施，但我发现它能带来出乎意料的性能提升。

你可能经历过这样的情况：向ChatGPT、Claude或Gemini提问，但得到的答案不尽人意，于是你提供关键反馈帮助LLM改进，最终获得更好的回答。如果这一提供关键反馈的步骤能自动化，让模型自我批评并优化输出呢？这正是“反思”策略的精髓所在。

以编程任务为例，我们首先让LLM直接生成完成特定任务X的代码。完成后，我们进一步引导它反思自身的输出，方式可能如下：

这是为完成任务X而编写的代码：
 [此前生成的代码] 
请细致审查代码的准确性、编程风格及效率，并提出改进意见。

这一过程有时能让LLM识别出问题并给出建设性的建议。之后，我们再次提示LLM，这次包括先前生成的代码和给出的改进意见，要求其根据反馈重新编写代码。这样的循环可能会带来更加精准的回答。通过不断的批评和重写，LLM能在包括编写代码、撰写文本、回答问题等多种任务上自我完善，发现并弥补不足。

而超越自我反思，我们还可以为LLM提供工具以帮助其评估输出。比如，通过运行一些单元测试来检查代码是否能在测试案例中得到正确的结果，或者搜索网络以验证文本输出的准确性。接着，它可以基于发现的错误进行反思，并提出改进方案。

此外，我们还可以采用多智能体框架来实施“反思”。通过创建两个不同角色的智能体——一个负责生成高质量的输出，另一个则专注于对前者的输出提出建设性批评，两个智能体之间的互动讨论促进了更佳的响应。

虽然“反思”是一种基本的智能体工作流程类型，但在实际应用中，我惊喜地发现它在一些案例中大幅提升了性能。我希望你也能在你的项目中尝试使用它。如果你对深入了解“反思”感兴趣，以下几篇论文值得一读：

\-《Self-Refine: Iterative Refinement with Self-Feedback》, 由 Madaan 等人于 2023 年发表
-《Reflexion: Language Agents with Verbal Reinforcement Learning》, 由 Shinn 等人于 2023 年发表
-《CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing》, 由 Gou 等人于 2024 年发表

未来，我还会介绍更多关于智能体设计模式的内容。

原文：https://t.co/86cn08KVw2 
#+END_QUOTE\
** 📌 [[2024-03-29]]
#+BEGIN_QUOTE
相关视频：https://t.co/BipNerkcXK 
#+END_QUOTE\