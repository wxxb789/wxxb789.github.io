:PROPERTIES:
:title: readwise/ğŸ¤–ï¸LLM Can Self-Improve ğŸ§ ...
:END:


* metadata
:PROPERTIES:
:author: [[jkronand on Twitter]]
:full-title: "ğŸ¤–ï¸LLM Can Self-Improve ğŸ§ ..."
:category: [[tweets]]
:url: https://twitter.com/jkronand/status/1621744876298833920
:image-url: https://pbs.twimg.com/profile_images/1635756469986689024/lPOWrGg5.jpg
:END:

* Highlights first synced by [[Readwise]] [[2023-12-22]]
** ğŸ“Œ [[2023-02-05]]
#+BEGIN_QUOTE
ğŸ¤–ï¸LLM can self-improve ğŸ§ 

1) Self-consistency boosts reasoning skills by sampling multiple paths & finding the most consistent answer

But more samples = more comp. requirements. ğŸ’»

2)  but we can train better LLM with self-generated solutions from 1)

https://t.co/kLfyCuc0uL 
#+END_QUOTE\
** ğŸ“Œ [[2023-02-05]]
#+BEGIN_QUOTE
The naive approach requires:

\- dataset of unlabeled questions
- few-shot chain of thought prompts to generate the "pseudo" labels for the self-train pass

Authors show one can also extend a dataset with synthetic questions, to get more pseudo labels, and improve results further 
#+END_QUOTE\