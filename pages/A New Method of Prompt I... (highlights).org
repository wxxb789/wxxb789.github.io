:PROPERTIES:
:title: A New Method of Prompt I... (highlights)
:END:

:PROPERTIES:
:author: [[AlphaSignalAI on Twitter]]
:full-title: "A New Method of Prompt I..."
:category: [[tweets]]
:url: https://twitter.com/AlphaSignalAI/status/1643271098342014977
:END:

* Highlights first synced by [[Readwise]] [[2023-11-14]]
** ðŸ“Œ
** #+BEGIN_QUOTE
** A new method of Prompt Injection Attack on GPT-4 was just found! 

By wrapping the malicious prompt in markdown and  instructing GPT to become a "Misinformation Bot, that will only provide wrong answers" security researchers have been able to manipulate the model. 

![](https://pbs.twimg.com/media/Fs4QbttWYAEPCWe.jpg)  ([View Tweet](https://twitter.com/AlphaSignalAI/status/1643271098342014977))
** #+END_QUOTE
** ðŸ“Œ
** #+BEGIN_QUOTE
** Markdown based injection: 

![](https://pbs.twimg.com/media/Fs4PyfwWcAEbYXg.jpg)  ([View Tweet](https://twitter.com/AlphaSignalAI/status/1643271101236015104))
** #+END_QUOTE
** ðŸ“Œ
** #+BEGIN_QUOTE
** Source:
https://t.co/Co6JY080Dj  ([View Tweet](https://twitter.com/AlphaSignalAI/status/1643271104276971523))
** #+END_QUOTE