:PROPERTIES:
:title: readwise/🔭 How to Reduce \#LLM Gen...
:END:


* metadata
:PROPERTIES:
:author: [[ShayneRedford on Twitter]]
:full-title: "🔭 How to Reduce \#LLM Gen..."
:category: [[tweets]]
:url: https://twitter.com/ShayneRedford/status/1628068629983150080
:image-url: https://pbs.twimg.com/profile_images/1668811167945441280/3rbesYxR.jpg
:END:

* Highlights first synced by [[Readwise]] [[2023-12-22]]
** 📌 [[2023-02-22]]
#+BEGIN_QUOTE
🔭 How to reduce #LLM generation toxicity/bias?

I'm surprised this finding hasn't received any attention:

Instruction Tuning (e.g. Flan, T0) reduces toxic generations A LOT ✨ w/o any Human Feedback ✨.

➡️ I.e. #ChatGPT-esque Human values alignment w/o human feedback.

1/ 

![](https://pbs.twimg.com/media/FpgPyQLaMAAu79D.jpg) 

![](https://pbs.twimg.com/media/FpgPyhWaEAEfsJe.jpg) 
#+END_QUOTE\
** 📌 [[2023-02-22]]
#+BEGIN_QUOTE
Buried in the Scaling Flan Appendix C:

1⃣ Generating toxic responses to non-toxic prompts (🔻 44% ➡️ 18%)
2⃣ Generating toxic responses to prompts on identity groups (🔻🔻)
3⃣ Ability to detect toxic content 0-shot (🔺14%+)

📜: https://t.co/lvYsx8kPfF

2/ 
#+END_QUOTE\
** 📌 [[2023-02-22]]
#+BEGIN_QUOTE
🌟 Finding 1⃣ 🌟

RealToxicityPrompts measures how often toxic / non-toxic prompts trigger biased/toxic/profane responses (rated by Perspective API).

RTP 📜: https://t.co/UcGsE9d8d0, @samgehman @ssgrn et al

Figures: Flan-PaLM's responses eval less toxic than PaLM's

3/ 

![](https://pbs.twimg.com/media/FpgPzE8agAAwcBV.png) 

![](https://pbs.twimg.com/media/FpgPzWVaMAAV0ag.jpg) 
#+END_QUOTE\
** 📌 [[2023-02-22]]
#+BEGIN_QUOTE
🌟 Finding 2⃣ 🌟

Responses to prompts for identity groups are systematically less toxic for Flan-PaLM than PaLM.

Figures: Religion/Gender/Ethnicity toxicities lower (L), though tail distribution toxicities aren't solved (R).

4/ 

![](https://pbs.twimg.com/media/FpgPz5sagAIiu7Z.jpg) 

![](https://pbs.twimg.com/media/FpgP0QJaMAEQ8MP.jpg) 
#+END_QUOTE\
** 📌 [[2023-02-22]]
#+BEGIN_QUOTE
🌟 Finding 3⃣ 🌟

LLMs' ability to identify whether text is toxic or not, using Civil Comments, is significantly improved (perhaps less surprising).

Civil Comments 📜: https://t.co/IjLhkDqOWI

Table: Flan-PaLM > PaLM by ~13%+ for 0-shot, and ~5%+ for 10-shot.

5/ 

![](https://pbs.twimg.com/media/FpgP0x6aAAAhKyC.png) 
#+END_QUOTE\
** 📌 [[2023-02-22]]
#+BEGIN_QUOTE
Why is this important?

New work shows larger models can harbor more bias (📜: https://t.co/TTKQC1MQot Ganguli, @AmandaAskell, @nschiefer et al.)

And larger models may hallucinate non-factual info more (https://t.co/cs8z1ka8Sz)

6/ 

![](https://pbs.twimg.com/media/FpgP1OwaYAAyb-E.jpg) 

![](https://pbs.twimg.com/media/FpgP1hNaAAYiH2b.jpg) 
#+END_QUOTE\
** 📌 [[2023-02-22]]
#+BEGIN_QUOTE
🌟 Take-aways 🌟

Much of the discussion on "alignment to human values" has centered on collecting human feedback signals to model responses.

But the Flan Collection is simply NLP tasks framed as instructions...

7/ 
#+END_QUOTE\
** 📌 [[2023-02-22]]
#+BEGIN_QUOTE
🌟 Take-aways 🌟

This isn't to say human feedback doesn't provide stronger benefits, but significant toxicity reduction (or better #AISafety) may be achievable with the tools we already have (simple instruction tuning), even without new large-scale collection efforts.

8/ 
#+END_QUOTE\
** 📌 [[2023-02-22]]
#+BEGIN_QUOTE
🌟 Take-aways 🌟

TLDR: Care about bias/toxicity? Use your favorite instruction-tuned model.

(Like Flan-T5: https://t.co/p7gVis9lHM!)

9/ 
#+END_QUOTE\
** 📌 [[2023-02-22]]
#+BEGIN_QUOTE
🌟 Limitations 🌟

➡️ Toxicity evals are imperfect and not comprehensive!
➡️ These evals are only English and western-centric
➡️ Review the paper for important details

10/ 
#+END_QUOTE\
** 📌 [[2023-02-22]]
#+BEGIN_QUOTE
Extra credit goes to Kevin Robinson, @Hou_Le, @m_pellat, Dasha Valter, @acastroros who ran these evals.

11/11 
#+END_QUOTE\
** 📌 [[2023-02-22]]
#+BEGIN_QUOTE
And thank you to @_jasonwei and @YiTayML for feedback on this thread! 
#+END_QUOTE\