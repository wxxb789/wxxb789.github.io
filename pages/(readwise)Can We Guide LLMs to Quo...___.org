:PROPERTIES:
:title: (readwise)Can We Guide LLMs to Quo...
:END:

:PROPERTIES:
:author: [[orionweller on Twitter]]
:full-title: "Can We Guide LLMs to Quo..."
:category: [[tweets]]
:url: https://twitter.com/orionweller/status/1660994241773047810
:image-url: https://pbs.twimg.com/profile_images/1339350166831210497/T6_oS5TW.jpg
:END:

* Highlights first synced by [[Readwise]] [[2023-12-05]]
** üìå
#+BEGIN_QUOTE
Can we guide LLMs to quote text from their pre-training data using prefixes like "According To ..", improving grounding and reducing hallucination? We discovered that LLMs do have this capability and can increase or decrease quoting on request ü§Ø

üìù:https://t.co/9E5YUiC4ZH 1/5 

![](https://pbs.twimg.com/media/Fw0JdY0aEAAoCWa.jpg) 
#+END_QUOTE
    date:: [[2023-05-24]]
*** from _Can We Guide LLMs to Quo..._ by @orionweller on Twitter
*** [View Tweet](https://twitter.com/orionweller/status/1660994241773047810)
** üìå
#+BEGIN_QUOTE
A challenge here is efficiently and scalably measuring an LLM's grounding (i.e., quoting from) in pre-training data. To tackle this, we present a new metric (QUIP-score) based on Data Portraits üñºÔ∏è, which evaluates the direct presence of LLM-generations in a given corpus. 2/5 
#+END_QUOTE
    date:: [[2023-05-24]]
*** from _Can We Guide LLMs to Quo..._ by @orionweller on Twitter
*** [View Tweet](https://twitter.com/orionweller/status/1660994245686366219)
** üìå
#+BEGIN_QUOTE
Excitingly, our experiments show that these "According To" prompts aimed at grounding LLMs significantly improve grounding under our metric (while anti-grounding prompts lower the score). Not only that, but According To prompts often improves the downstream task performance! 3/5 

![](https://pbs.twimg.com/media/Fw0Jd_3acAQJywQ.jpg) 
#+END_QUOTE
    date:: [[2023-05-24]]
*** from _Can We Guide LLMs to Quo..._ by @orionweller on Twitter
*** [View Tweet](https://twitter.com/orionweller/status/1660994255157071872)
** üìå
#+BEGIN_QUOTE
We also conduct scaling experiments with LLMs of different sizes. As the model size grows, their capacity to quote from pre-training increases (on both OpenAI and open-sourced models). 

![](https://pbs.twimg.com/media/Fw0JehraEAANPyV.png) 
#+END_QUOTE
    date:: [[2023-05-24]]
*** from _Can We Guide LLMs to Quo..._ by @orionweller on Twitter
*** [View Tweet](https://twitter.com/orionweller/status/1660994264149659648)
** üìå
#+BEGIN_QUOTE
We've got a lot of other great analysis in the paper on instruction-tuning and entity popularity, so check it out!

Special thanks to my coauthors @ruyimarone, @Nathaniel_Weir,  @lawrie_dawn, @DanielKhashabi, and @ben_vandurme at @jhuclsp #NLProc 5/5 
#+END_QUOTE
    date:: [[2023-05-24]]
*** from _Can We Guide LLMs to Quo..._ by @orionweller on Twitter
*** [View Tweet](https://twitter.com/orionweller/status/1660994267366694913)