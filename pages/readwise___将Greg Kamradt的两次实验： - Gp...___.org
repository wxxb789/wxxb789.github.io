:PROPERTIES:
:title: readwise/将Greg Kamradt的两次实验： - Gp...
:END:

:PROPERTIES:
:author: [[dotey on Twitter]]
:full-title: "将Greg Kamradt的两次实验： - Gp..."
:category: [[tweets]]
:url: https://twitter.com/dotey/status/1727454708627808261
:image-url: https://pbs.twimg.com/profile_images/561086911561736192/6_g58vEs.jpeg
:END:

* Highlights first synced by [[Readwise]] [[2023-12-18]]
** 📌
#+BEGIN_QUOTE
将Greg Kamradt的两次实验：
\- GPT-4-128K https://t.co/e4hBVBj7TF
- Claude 2.1 200K：https://t.co/KzG3bIWZNJ 

两次结果放一起对比，可以看到：

GPT-4-128K
1. 在上下文长度小于 73K Tokens时，不会有信息遗忘
2. 在上下文长度超出 73K 后，位于中间7%-50% 区间的信息可能会被遗忘

Claude-2.1-200K
1. 上下文长度小于24K时效果最好，几乎不会有信息遗忘
2. 上下文长度超过24K就开始变差，90K后，效果很差，一大半信息会遗忘
3. 最头部和最顶部的1%效果最好，不会被遗忘

我的总结
1. GPT-4还是最强的
2. 尽量少一些上下文，长文还是需要手动或者自动分割，GPT-4 的话，不要超过73K（输入输出加一起）
3. System Prompt 放在最前或者最后都可以，放在后面更好
4. 如果System Prompt 放在前面，对于GPT-4来说，不要超过5%，对于Claude来说不要超过1%
4. GPTs的Prompt只能放在最前面，所以不要超过不要超过5%也就是128*0.05 = 6.4 K Tokens比较好<img src='https://pbs.twimg.com/media/F_kl-_GXkAAKzcf.jpg'/><img src='https://pbs.twimg.com/media/F_kmA7SXIAAjIF9.jpg'/> 
#+END_QUOTE
    date:: [[2023-11-23]]
*** from _将Greg Kamradt的两次实验： - Gp..._ by @dotey on Twitter
*** [View Tweet](https://twitter.com/dotey/status/1727454708627808261)
** 📌
#+BEGIN_QUOTE
我让GPT-4V帮我分析了一下两张图：

\----

由于我无法同时访问两张图片，我将分别对每张图片进行解读，然后基于我的解读进行对比分析。

对于第一张图片：

这是一个关于机器学习模型（称为Claude 2.1）的性能测试图。测试的目的是评估模型在不同文档深度和上下文长度下检索信息的准确性。图中的矩阵表格显示了不同的上下文长度（标记为“Context Length (# Tokens)”）和文档深度百分比（从顶部到底部）。颜色代码表示检索准确性，从绿色（更高准确性）到红色（较低准确性）。注释指出，随着上下文长度的增加，Claude 2.1的检索准确性逐渐下降。这表明模型在处理大量数据时可能会遇到困难。

对于第二张图片：

这张图与第一张相似，但针对的是不同的机器学习模型，即GPT-4。测试的目的是评估GPT-4在不同文档深度和上下文长度下的信息检索准确性。这张图同样显示了一个由不同上下文长度和文档深度组成的矩阵，并用颜色代码表示检索准确性。注释指出，当事实被放置在文档深度的10%-50%之间时，GPT-4的检索准确性开始下降，尤其是在大的上下文长度时。

对比分析：

两张图展示了两种不同的模型在不同条件下的性能测试。主要的比较点在于模型处理大量信息时的准确性。Claude 2.1的测试覆盖了更宽的上下文长度范围，而GPT-4的测试似乎集中在更小的数据集上，但进行了更多的样本测试以增加结果的稳定性。两张图表的颜色渐变表明，两个模型都在较大的上下文长度下表现出检索准确性下降的趋势，尽管具体的准确性水平和下降趋势在每个模型中是不同的。这些测试对于理解和改进机器学习模型在处理大规模数据时的性能至关重要。<img src='https://pbs.twimg.com/media/F_ko1XOW8AETUYy.jpg'/> 
#+END_QUOTE
    date:: [[2023-11-23]]
*** from _将Greg Kamradt的两次实验： - Gp..._ by @dotey on Twitter
*** [View Tweet](https://twitter.com/dotey/status/1727456845646733767)