:PROPERTIES:
:title: 什么是 AI Agent？相比原生 LLM 的推... (highlights)
:END:

:PROPERTIES:
:author: [[Barret_China on Twitter]]
:full-title: "什么是 AI Agent？相比原生 LLM 的推..."
:category: [[tweets]]
:url: https://twitter.com/Barret_China/status/1725386494716850455
:END:

* Highlights first synced by [[Readwise]] [[2023-11-17]]
** 📌
** #+BEGIN_QUOTE
** 什么是 AI Agent？相比原生 LLM 的推理，Agent 能带来了哪些能力？为什么 Agent 需要具备这些能力？

人类在决策的时候有两种思维模式，诺奖得主 Daniel Kahneman 称之为第一系统和第二系统思维。第一系统（System 1）是快速的、习惯性的、无意识的，第二系统（System 2）是深思熟虑的、自主的、有意识的。

LLM 的作用就是进行 Next Token Generation，它的表现跟 System 1 基本一致，也正因为这本能式的推理反应，LLM 会出现很多思维谬误和幻觉问题；AI Agent 可以帮助 LLM 搭建一套框架来进行深度思考和分析，激发 System 2 的潜力，从而做出更复杂和可靠的决策，之前提到过很多让 ChatGPT 加强思考的方法，例如 CoT（Chain of Thought）和 ToT（Tree of Thought）等，都是为了阻止 LLM 直线式思考，让它在触碰最终答案之前，迂回几次，试探更多的路径，剔除掉更多低置信度的选项。

这篇文论（https://t.co/MRKnNVZGBs）对 Agent 做了一个新的定义：具有自主性、反应性、积极性和社交能力特征的智能实体。人类的终极目标是期望 AI 能够自规划执行解决复杂的问题，很显然，单凭 CoT/ToT 这些简单的 System 2 思考策略是远远不够的，那还需要哪些东西呢？

目前已知的能够很好提升效果的办法包括：1）让多 Agents 进行相互系统；2）能够与环境进行交互；3）具备中短期甚至长期的记忆能力；4）能够在寻求答案的过程中更智能的决策和选择最佳路径。ChatGPT 的 GPTs 提供了上传资料、执行代码、函数调用等能力，本质上也是在补齐 System 2 的能力，等到 GPTs 的生态丰富之后，也可以实现 GPTs 之间的调用，这样就很容易构造一个西部世界了。

十分推荐阅读这篇文章的第一部分，《关于 AI agent 的四个关键问题》，https://t.co/KY6NH6j0EM，文章的第二部分和第三部分讲的是基于 AI Agent 的一些业界实践，以及未来需要去解决的一些问题，文章通俗易懂。<img src='https://pbs.twimg.com/media/F_HNgfMbcAAnAoO.jpg'/>  ([View Tweet](https://twitter.com/Barret_China/status/1725386494716850455))
** #+END_QUOTE