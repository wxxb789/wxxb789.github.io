:PROPERTIES:
:title: readwise/论文阅读：FrugalGPT，降低LLM的成本。...
:END:


* metadata
:PROPERTIES:
:author: [[9hills on Twitter]]
:full-title: "论文阅读：FrugalGPT，降低LLM的成本。..."
:category: [[tweets]]
:url: https://twitter.com/9hills/status/1656125779569430528
:image-url: https://pbs.twimg.com/profile_images/1509120377816969223/qzJBlcuS.jpg
:END:

* Highlights first synced by [[Readwise]] [[2023-12-22]]
** 📌 [[2023-05-10]]
#+BEGIN_QUOTE
论文阅读：FrugalGPT，降低LLM的成本。

常规方法：
1. 优化 Prompt
2. Query 合并
3. 语义相似缓存
4. 使用贵模型对便宜模型微调

LLM 级联：（重点）
5. 便宜模型回答后对回答自动打分，分数过低则调用更贵的模型，直到调用 GPT-4

感觉可以用 LangChain 自己实现一个。

https://t.co/TFzmogp5X9 

![](https://pbs.twimg.com/media/Fvu8n1faMAAk5T_.jpg) 
#+END_QUOTE\
** 📌 [[2023-05-10]]
#+BEGIN_QUOTE
这个事情的难点是 score function，打分模型。

论文中说是训练一个本地小模型用来打分，那这个小模型就比较类似于 RHLF 中的奖励模型。

这部分做好了比较难，可能从某个特定领域做一个特定领域的奖励模型比较好。 
#+END_QUOTE\